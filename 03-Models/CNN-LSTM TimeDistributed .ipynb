{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69703929",
   "metadata": {},
   "source": [
    "# CNN-LSTM TimeDistributed Tackle Probability Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d3d596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c53705a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameId</th>\n",
       "      <th>playId</th>\n",
       "      <th>nflId</th>\n",
       "      <th>frameId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>unitDir</th>\n",
       "      <th>unitO</th>\n",
       "      <th>force</th>\n",
       "      <th>home</th>\n",
       "      <th>...</th>\n",
       "      <th>defendersInTheBox</th>\n",
       "      <th>offenseFormation</th>\n",
       "      <th>absoluteYardlineNumber</th>\n",
       "      <th>timeSinceStart</th>\n",
       "      <th>surface</th>\n",
       "      <th>inside_outside</th>\n",
       "      <th>presnapDefScoreDiff</th>\n",
       "      <th>weight</th>\n",
       "      <th>position</th>\n",
       "      <th>gamePlayId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.022091e+09</td>\n",
       "      <td>56.0</td>\n",
       "      <td>38577.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.89</td>\n",
       "      <td>28.74</td>\n",
       "      <td>87.71</td>\n",
       "      <td>79.47</td>\n",
       "      <td>288.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>SHOTGUN</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>turf</td>\n",
       "      <td>inside</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>ILB</td>\n",
       "      <td>2022090800.056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.022091e+09</td>\n",
       "      <td>56.0</td>\n",
       "      <td>41239.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.85</td>\n",
       "      <td>29.96</td>\n",
       "      <td>247.65</td>\n",
       "      <td>276.16</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>SHOTGUN</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>turf</td>\n",
       "      <td>inside</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>DT</td>\n",
       "      <td>2022090800.056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.022091e+09</td>\n",
       "      <td>56.0</td>\n",
       "      <td>42816.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>49.38</td>\n",
       "      <td>7.66</td>\n",
       "      <td>8.33</td>\n",
       "      <td>61.57</td>\n",
       "      <td>346.254545</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>SHOTGUN</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>turf</td>\n",
       "      <td>inside</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>CB</td>\n",
       "      <td>2022090800.056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.022091e+09</td>\n",
       "      <td>56.0</td>\n",
       "      <td>43294.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.85</td>\n",
       "      <td>37.85</td>\n",
       "      <td>268.50</td>\n",
       "      <td>230.96</td>\n",
       "      <td>116.290909</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>SHOTGUN</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>turf</td>\n",
       "      <td>inside</td>\n",
       "      <td>0</td>\n",
       "      <td>208</td>\n",
       "      <td>CB</td>\n",
       "      <td>2022090800.056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.022091e+09</td>\n",
       "      <td>56.0</td>\n",
       "      <td>43298.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.89</td>\n",
       "      <td>33.14</td>\n",
       "      <td>293.53</td>\n",
       "      <td>249.12</td>\n",
       "      <td>241.090909</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>SHOTGUN</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>turf</td>\n",
       "      <td>inside</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>DE</td>\n",
       "      <td>2022090800.056.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gameId  playId    nflId  frameId      x      y  unitDir   unitO  \\\n",
       "0  2.022091e+09    56.0  38577.0      6.0  41.89  28.74    87.71   79.47   \n",
       "1  2.022091e+09    56.0  41239.0      6.0  27.85  29.96   247.65  276.16   \n",
       "2  2.022091e+09    56.0  42816.0      6.0  49.38   7.66     8.33   61.57   \n",
       "3  2.022091e+09    56.0  43294.0      6.0  41.85  37.85   268.50  230.96   \n",
       "4  2.022091e+09    56.0  43298.0      6.0  27.89  33.14   293.53  249.12   \n",
       "\n",
       "        force  home  ...  defendersInTheBox  offenseFormation  \\\n",
       "0  288.200000     1  ...                6.0           SHOTGUN   \n",
       "1  364.000000     1  ...                6.0           SHOTGUN   \n",
       "2  346.254545     1  ...                6.0           SHOTGUN   \n",
       "3  116.290909     1  ...                6.0           SHOTGUN   \n",
       "4  241.090909     1  ...                6.0           SHOTGUN   \n",
       "\n",
       "   absoluteYardlineNumber  timeSinceStart  surface  inside_outside  \\\n",
       "0                      85               0     turf          inside   \n",
       "1                      85               0     turf          inside   \n",
       "2                      85               0     turf          inside   \n",
       "3                      85               0     turf          inside   \n",
       "4                      85               0     turf          inside   \n",
       "\n",
       "   presnapDefScoreDiff  weight position        gamePlayId  \n",
       "0                    0     242      ILB  2022090800.056.0  \n",
       "1                    0     280       DT  2022090800.056.0  \n",
       "2                    0     184       CB  2022090800.056.0  \n",
       "3                    0     208       CB  2022090800.056.0  \n",
       "4                    0     240       DE  2022090800.056.0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import a small sample of the data\n",
    "df = pd.read_csv(\"sample_data.csv\")\n",
    "df = df.drop(columns='Unnamed: 0')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dde5beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_tensors: function to convert data into tensors for use in pytorch\n",
    "#input: data and taget variable\n",
    "#returns 3 tensors: x, y, and mask tensors\n",
    "def data_tensors(data, target):\n",
    "    #import libraries\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    from torch.nn.utils.rnn import pad_sequence\n",
    "    import torch.nn.functional as F\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "    #Preprocess data correctly\n",
    "    #target variables\n",
    "    target_variables = [\"tackle_binary_single\",\"tackle_binary_all\", \"tackle_nonbinary_all\", \"tackle_nonbinary_single\"]\n",
    "\n",
    "    #determine target variables to remove\n",
    "    target_variables.remove(target)\n",
    "\n",
    "    # remove unwanted variables \n",
    "    df = data.drop([\"gameId\",\"playId\",\"nflId\"], axis = 1)\n",
    "    df = df.drop(target_variables, axis = 1)\n",
    "\n",
    "    # Separate numerical and categorical variables\n",
    "    numerical_vars = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_vars = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "    # Define variables to exclude\n",
    "    exclude_scaling = ['gameId', 'frameId', 'home'] #might need to change this depending on added variables\n",
    "    exclude_scaling.append(target)\n",
    "    exclude_ohe = ['gamePlayId']\n",
    "\n",
    "    # Scale numerical variables using StandardScaler, excluding variables\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_vars.difference(exclude_scaling)] = scaler.fit_transform(df[numerical_vars.difference(exclude_scaling)])\n",
    "\n",
    "    # One-hot encode categorical variables\n",
    "    df = pd.get_dummies(df, columns=categorical_vars.difference(exclude_ohe), drop_first=True)\n",
    "\n",
    "    ############################################################################################\n",
    "    #Group data into correct array format\n",
    "\n",
    "    # Group data by 'gamePlayId'\n",
    "    plays_grouped = df.groupby('gamePlayId')\n",
    "\n",
    "    # Determine the maximum number of frames per play and rows per frame\n",
    "    max_frames_per_play = 140 #We found that the max number of frames per play in our data if 140\n",
    "    max_rows_per_frame = 11 #Set this to 11 players just a precaution, but all frames have ll players on a given frame in our data\n",
    "    num_feature_cols = df.shape[1] - 3 #number of columns - we are droping gamePlayId, frameId, and target\n",
    "\n",
    "    #Columns to drop in loop\n",
    "    cols_to_drop = ['gamePlayId', 'frameId', 'tackle_binary_single']\n",
    "\n",
    "    # Initialize lists for all plays' features, labels, and masks\n",
    "    all_play_features = []\n",
    "    all_play_labels = []\n",
    "    all_play_masks = []\n",
    "\n",
    "    for play_id, play_data in plays_grouped:\n",
    "        # Group by 'frameId' within each play\n",
    "        frames_grouped = play_data.groupby('frameId')\n",
    "        \n",
    "        # Initialize lists for all frames within a play (features, labels, and masks)\n",
    "        play_features = []\n",
    "        play_labels = []\n",
    "        play_masks = []\n",
    "\n",
    "        for frame_id, frame_data in frames_grouped:\n",
    "            #drop grouping variables and target variable\n",
    "            features = frame_data.drop(cols_to_drop, axis=1).values #remove the grouping variables\n",
    "            labels = frame_data['tackle_binary_single'].values\n",
    "\n",
    "            # Calculate current frame length\n",
    "            frame_length = len(features)\n",
    "\n",
    "            # Pad each frame's features and labels to have the same number of rows\n",
    "            padded_features = np.pad(features, ((0, max_rows_per_frame - frame_length), (0, 0)), mode='constant', constant_values=0)\n",
    "            padded_labels = np.pad(labels, (0, max_rows_per_frame - frame_length), mode='constant', constant_values=0)\n",
    "            \n",
    "            # Create mask for the current frame\n",
    "            mask = np.ones(max_rows_per_frame)\n",
    "            mask[:frame_length] = 1  # Actual data\n",
    "            mask[frame_length:] = 0  # Padded data\n",
    "\n",
    "            play_features.append(padded_features)\n",
    "            play_labels.append(padded_labels)\n",
    "            play_masks.append(mask)\n",
    "\n",
    "        frames_to_pad = max_frames_per_play - len(play_features)\n",
    "        play_features += [np.zeros((max_rows_per_frame, num_feature_cols)) for _ in range(frames_to_pad)]\n",
    "        play_labels += [np.zeros((max_rows_per_frame,)) for _ in range(frames_to_pad)]\n",
    "        play_masks += [np.zeros((max_rows_per_frame,)) for _ in range(frames_to_pad)]\n",
    "\n",
    "        all_play_features.append(play_features)\n",
    "        all_play_labels.append(play_labels)\n",
    "        all_play_masks.append(play_masks)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    x = np.array(all_play_features, dtype=np.float32)\n",
    "    y = np.array(all_play_labels, dtype=np.float32)\n",
    "    mask_array = np.array(all_play_masks, dtype=np.float32)\n",
    "\n",
    "\n",
    "    # Convert to PyTorch tensors and return them\n",
    "    return torch.from_numpy(x), torch.from_numpy(y), torch.from_numpy(mask_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20a52aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([11, 140, 11, 77])\n",
      "y_train shape: torch.Size([11, 140, 11])\n",
      "x_test shape: torch.Size([3, 140, 11, 77])\n",
      "y_test shape: torch.Size([3, 140, 11])\n"
     ]
    }
   ],
   "source": [
    "# Prepare & split the data \n",
    "target_variable = 'tackle_binary_single'\n",
    "x_data, y_data, mask_data = data_tensors(df, target_variable)\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Total number of plays\n",
    "total_plays = x_data.size(0)\n",
    "\n",
    "# Calculate the number of plays in the training set\n",
    "num_train_plays = int(total_plays * split_ratio)\n",
    "\n",
    "# Splitting the tensors into training and testing sets\n",
    "x_train = x_data[:num_train_plays]\n",
    "y_train = y_data[:num_train_plays]\n",
    "mask_train = mask_data[:num_train_plays]\n",
    "\n",
    "x_test = x_data[num_train_plays:]\n",
    "y_test = y_data[num_train_plays:]\n",
    "mask_test = mask_data[num_train_plays:]\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "985689d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after Conv2D: torch.Size([140, 32, 11, 77])\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define and Test Model with Conv2D Layer Only\n",
    "class CNNModelTest(nn.Module):\n",
    "    def __init__(self, num_players, num_features):\n",
    "        super(CNNModelTest, self).__init__()\n",
    "        self.conv2d = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), stride=1, padding='same')\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, timesteps, players, features = x.size()\n",
    "        x = x.view(batch_size * timesteps, 1, players, features)  # Adding channel dimension\n",
    "        x = F.relu(self.conv2d(x))\n",
    "        return x\n",
    "\n",
    "# Define the model\n",
    "model_test = CNNModelTest(num_players=11, num_features=77)\n",
    "\n",
    "# Forward pass with test data\n",
    "x_sample = x_train[:1]  # Using only the first play for testing\n",
    "output = model_test(x_sample)\n",
    "print(\"Output shape after Conv2D:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c568cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after LSTM: torch.Size([1, 140, 50])\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Add LSTM Layer\n",
    "class CNNLSTMModelTest(nn.Module):\n",
    "    def __init__(self, num_players, num_features, hidden_size):\n",
    "        super(CNNLSTMModelTest, self).__init__()\n",
    "        self.conv2d = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), stride=1, padding='same')\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Placeholder for LSTM input size\n",
    "        self.lstm_input_size = None  \n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=hidden_size, batch_first=True)  # Initialize with placeholder input size\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, timesteps, players, features = x.size()\n",
    "        x = x.view(batch_size * timesteps, 1, players, features)\n",
    "        x = F.relu(self.conv2d(x))\n",
    "\n",
    "        # Dynamically calculate LSTM input size based on Conv2D output size\n",
    "        if self.lstm_input_size is None:\n",
    "            _, C, H, W = x.size()\n",
    "            self.lstm_input_size = C * H * W\n",
    "            self.lstm = nn.LSTM(input_size=self.lstm_input_size, hidden_size=self.hidden_size, batch_first=True)\n",
    "\n",
    "        # Reshape for LSTM\n",
    "        x = x.view(batch_size, timesteps, -1)\n",
    "        lstm_out, (hn, cn) = self.lstm(x)\n",
    "        return lstm_out\n",
    "\n",
    "# Instantiate the model\n",
    "model_test = CNNLSTMModelTest(num_players=11, num_features=77, hidden_size=50)\n",
    "\n",
    "# Forward pass with test data\n",
    "output = model_test(x_sample)\n",
    "print(\"Output shape after LSTM:\", output.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2c00c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after fully connected layer: torch.Size([1, 140, 11, 1])\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Adding the Fully Connected Layer (TimeDistributed equivalent)\n",
    "class CNNLSTMModel(nn.Module):\n",
    "    def __init__(self, num_players, num_features, hidden_size, num_classes):\n",
    "        super(CNNLSTMModel, self).__init__()\n",
    "        self.conv2d = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), stride=1, padding='same')\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm_input_size = None\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=hidden_size, batch_first=True)  # Placeholder input size\n",
    "        self.fc = nn.Linear(hidden_size, num_players * num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, timesteps, players, features = x.size()\n",
    "        x = x.view(batch_size * timesteps, 1, players, features)\n",
    "        x = F.relu(self.conv2d(x))\n",
    "\n",
    "        if self.lstm_input_size is None:\n",
    "            _, C, H, W = x.size()\n",
    "            self.lstm_input_size = C * H * W\n",
    "            self.lstm = nn.LSTM(input_size=self.lstm_input_size, hidden_size=self.hidden_size, batch_first=True)\n",
    "\n",
    "        x = x.view(batch_size, timesteps, -1)\n",
    "        lstm_out, (hn, cn) = self.lstm(x)\n",
    "\n",
    "        # Apply the fully connected layer\n",
    "        out = self.fc(lstm_out)\n",
    "        out = out.view(batch_size, timesteps, players, -1)\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# Define and test the full model\n",
    "model = CNNLSTMModel(num_players=11, num_features=77, hidden_size=50, num_classes=1)\n",
    "output = model(x_sample)\n",
    "print(\"Output shape after fully connected layer:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5e0f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizer (You can choose optimizers like Adam, SGD, etc.)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ee546d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7069582451473583\n",
      "Epoch 2, Loss: 0.7052704420956698\n",
      "Epoch 3, Loss: 0.7038454846902327\n",
      "Epoch 4, Loss: 0.702070106159557\n",
      "Epoch 5, Loss: 0.7009985175999728\n",
      "Epoch 6, Loss: 0.7002423026344993\n",
      "Epoch 7, Loss: 0.6995979655872692\n",
      "Epoch 8, Loss: 0.6988450559702787\n",
      "Epoch 9, Loss: 0.6983056122606451\n",
      "Epoch 10, Loss: 0.6979116255586798\n",
      "Epoch 11, Loss: 0.697566731409593\n",
      "Epoch 12, Loss: 0.6972624876282432\n",
      "Epoch 13, Loss: 0.6969924135641619\n",
      "Epoch 14, Loss: 0.6967510851946744\n",
      "Epoch 15, Loss: 0.6965342976830222\n",
      "Epoch 16, Loss: 0.6963327418674122\n",
      "Epoch 17, Loss: 0.6961363174698569\n",
      "Epoch 18, Loss: 0.69589825110002\n",
      "Epoch 19, Loss: 0.6957297162576155\n",
      "Epoch 20, Loss: 0.6955983747135509\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Assuming x_train and y_train are lists of tensors\n",
    "    for inputs, labels in zip(x_train, y_train):\n",
    "        # Add a batch dimension to inputs and labels\n",
    "        inputs = inputs.unsqueeze(0)  # Shape: [1, 140, 11, 77]\n",
    "        labels = labels.unsqueeze(0)  # Shape: [1, 140, 11]\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.unsqueeze(-1))  # Add the channel dimension to labels\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print statistics\n",
    "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(x_train)}')\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "207da1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 0.6955373287200928\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0.0\n",
    "num_batches = 0\n",
    "\n",
    "with torch.no_grad():  # No need to track gradients during evaluation\n",
    "    for inputs, labels in zip(x_test, y_test):\n",
    "        # Add a batch dimension to inputs and labels\n",
    "        inputs = inputs.unsqueeze(0)  # Shape: [1, 140, 11, 77]\n",
    "        labels = labels.unsqueeze(0)  # Shape: [1, 140, 11]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.unsqueeze(-1))  # Add the channel dimension to labels for BCELoss\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "average_test_loss = test_loss / num_batches\n",
    "print(f'Average Test Loss: {average_test_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70a5d174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Precision, Recall, and F1 Score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Variables to hold predictions and true labels\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Evaluate model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in zip(x_test, y_test):\n",
    "        inputs = inputs.unsqueeze(0)  # Add batch dimension\n",
    "        labels = labels.unsqueeze(0)  # Add batch dimension\n",
    "        outputs = model(inputs)\n",
    "        all_predictions.append(outputs.view(-1).cpu().numpy())\n",
    "        all_labels.append(labels.view(-1).cpu().numpy())\n",
    "\n",
    "# Flatten the lists\n",
    "all_predictions = np.hstack(all_predictions)\n",
    "all_labels = np.hstack(all_labels)\n",
    "\n",
    "# Calculate metrics\n",
    "# precision = precision_score(all_labels, all_predictions)\n",
    "# recall = recall_score(all_labels, all_predictions)\n",
    "# f1 = f1_score(all_labels, all_predictions)\n",
    "\n",
    "# print(f'Precision: {precision}, Recall: {recall}, F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b19feec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0172578 , 0.01510831, 0.01476363, ..., 0.0055955 , 0.0048889 ,\n",
       "       0.00438096], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ad4acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
