{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Preparation\n",
    "The following notebook contains the neccessary functions to prepare data into tensors for proper neural network use given the architecture of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_tensors_cnn_4d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data_tensor_cnn_4d function performs the following operations on the data to prep for the model:\n",
    "1. Remove unwanted target variables, nflId, gameId, and playId\n",
    "2. Scale numerical data, excluding the gamePlayId, frameId, and binary values\n",
    "3. One-hot encode all categorical variables \n",
    "4. Group plays and frames into data \"images\" of player data on a given frame\n",
    "5. Pad arrays for consitent tensor datatypes \n",
    "6. Create mask array with a 1 to identify frames that were actual data and 0 to identify padded values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_tensors_cnn_4d(data, target, is_synthetic=False):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    from torch.nn.utils.rnn import pad_sequence\n",
    "    import torch.nn.functional as F\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    \n",
    "    if is_synthetic:\n",
    "        #tranform gamePlayId variable to account for synthetic data\n",
    "        # Create a mask to identify duplicates based on 'gamePlayId', 'frameId', and 'nflId'\n",
    "        duplicates_mask = data.duplicated(subset=['gamePlayId', 'frameId', 'nflId'], keep='first')\n",
    "\n",
    "        # Add '.1' to 'gamePlayId' for the second occurrence of each duplicate\n",
    "        data.loc[duplicates_mask, 'gamePlayId'] += '.1'\n",
    "\n",
    "    # Preprocess data correctly\n",
    "    # Target variables\n",
    "    target_variables = [\"tackle_binary_single\",\"tackle_binary_all\", \"tackle_nonbinary_all\", \"tackle_nonbinary_single\"]\n",
    "\n",
    "    # Determine target variables to remove\n",
    "    target_variables.remove(target)\n",
    "\n",
    "    # Remove unwanted variables \n",
    "    df = data.drop([\"gameId\",\"playId\",], axis=1)\n",
    "    df = df.drop(target_variables, axis=1)\n",
    "\n",
    "    # Separate numerical and categorical variables\n",
    "    numerical_vars = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_vars = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "    # Define variables to exclude\n",
    "    exclude_scaling = ['gameId', 'frameId','nflId', 'home'] # Might need to change this depending on added variables\n",
    "    exclude_scaling.append(target)\n",
    "    exclude_ohe = ['gamePlayId']\n",
    "\n",
    "    # Scale numerical variables using StandardScaler, excluding variables\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_vars.difference(exclude_scaling)] = scaler.fit_transform(df[numerical_vars.difference(exclude_scaling)])\n",
    "\n",
    "    # One-hot encode categorical variables\n",
    "    df = pd.get_dummies(df, columns=categorical_vars.difference(exclude_ohe), drop_first=True)\n",
    "\n",
    "    ############################################################################################\n",
    "    # Group data into correct array format\n",
    "\n",
    "    # Group data by 'gamePlayId'\n",
    "    plays_grouped = df.groupby('gamePlayId')\n",
    "\n",
    "    # Determine the maximum number of frames per play and rows per frame\n",
    "    max_frames_per_play = 140 # We found that the max number of frames per play in our data if 140\n",
    "    max_rows_per_frame = 11 # Set this to 11 players just a precaution, but all frames have all players on a given frame in our data\n",
    "    num_feature_cols = df.shape[1] - 4 # Number of columns - we are dropping gamePlayId, frameId, nflId and target\n",
    "\n",
    "    # Columns to drop in loop\n",
    "    cols_to_drop = ['gamePlayId', 'frameId','nflId', 'tackle_binary_single']\n",
    "\n",
    "    # Initialize lists for all plays' features, labels, and masks\n",
    "    all_play_features = []\n",
    "    all_play_labels = []\n",
    "    all_play_masks = []\n",
    "    gamePlayId_list = []\n",
    "    nflId_list = []\n",
    "    frameId_list = []\n",
    "\n",
    "    for play_id, play_data in plays_grouped:\n",
    "        # Group by 'frameId' within each play\n",
    "        frames_grouped = play_data.groupby('frameId')\n",
    "        \n",
    "        # Initialize lists for all frames within a play (features, labels, and masks)\n",
    "        play_features = []\n",
    "        play_labels = []\n",
    "        play_masks = []\n",
    "        play_gamePlayId_list = []\n",
    "        play_nflId_list = []\n",
    "        play_frameId_list = []\n",
    "\n",
    "        for frame_id, frame_data in frames_grouped:\n",
    "            # Drop grouping variables and target variable\n",
    "            features = frame_data.drop(cols_to_drop, axis=1).values # Remove the grouping variables\n",
    "            labels = frame_data['tackle_binary_single'].values\n",
    "\n",
    "            # Extract the game, play, nflId, and frameId values for this player's data\n",
    "            gamePlayId = frame_data['gamePlayId'].values[0]\n",
    "            nflId = frame_data['nflId'].values[0]\n",
    "            frameId = frame_data['frameId'].values[0]\n",
    "\n",
    "            # Calculate current frame length\n",
    "            frame_length = len(features)\n",
    "\n",
    "            # Pad each frame's features and labels to have the same number of rows\n",
    "            padded_features = np.pad(features, ((0, max_rows_per_frame - frame_length), (0, 0)), mode='constant', constant_values=0)\n",
    "            padded_labels = np.pad(labels, (0, max_rows_per_frame - frame_length), mode='constant', constant_values=0)\n",
    "            \n",
    "            # Create mask for the current frame\n",
    "            mask = np.ones(max_rows_per_frame)\n",
    "            mask[:frame_length] = 1  # Actual data\n",
    "            mask[frame_length:] = 0  # Padded data\n",
    "\n",
    "            play_features.append(padded_features)\n",
    "            play_labels.append(padded_labels)\n",
    "            play_masks.append(mask)\n",
    "            \n",
    "            # Extend the gameId, playId, nflId, and frameId lists\n",
    "            play_gamePlayId_list.extend([gamePlayId] * max_rows_per_frame)\n",
    "            play_nflId_list.extend([nflId] * max_rows_per_frame)\n",
    "            play_frameId_list.extend([frameId + i for i in range(max_rows_per_frame)])\n",
    "\n",
    "        frames_to_pad = max_frames_per_play - len(play_features)\n",
    "        play_features += [np.zeros((max_rows_per_frame, num_feature_cols)) for _ in range(frames_to_pad)]\n",
    "        play_labels += [np.zeros((max_rows_per_frame,)) for _ in range(frames_to_pad)]\n",
    "        play_masks += [np.zeros((max_rows_per_frame,)) for _ in range(frames_to_pad)]\n",
    "        \n",
    "        # Extend the ID lists for the padding frames\n",
    "        play_gamePlayId_list.extend([gamePlayId] * max_rows_per_frame * frames_to_pad)\n",
    "        play_nflId_list.extend([nflId] * max_rows_per_frame * frames_to_pad)\n",
    "        play_frameId_list.extend([frameId + max_rows_per_frame * i for i in range(frames_to_pad) for _ in range(max_rows_per_frame)])\n",
    "\n",
    "\n",
    "        all_play_features.append(play_features)\n",
    "        all_play_labels.append(play_labels)\n",
    "        all_play_masks.append(play_masks)\n",
    "        gamePlayId_list.extend(play_gamePlayId_list)\n",
    "        nflId_list.extend(play_nflId_list)\n",
    "        frameId_list.extend(play_frameId_list)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    x = np.array(all_play_features, dtype=np.float32)\n",
    "    y = np.array(all_play_labels, dtype=np.int64)\n",
    "    mask_array = np.array(all_play_masks, dtype=np.int64)\n",
    "\n",
    "    # Create a DataFrame to hold gameId, playId, nflId, and frameId values\n",
    "    id_data = pd.DataFrame({'gamePlayId': gamePlayId_list, 'nflId': nflId_list, 'frameId': frameId_list})\n",
    "\n",
    "    # Convert to PyTorch tensors and return them along with id_data\n",
    "    return torch.from_numpy(x), torch.from_numpy(y), torch.from_numpy(mask_array), id_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#train_samp = pd.read_csv(\"../Data/train_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, y, mask, id_data = data_tensors(train_samp, \"tackle_binary_single\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1309, 140, 11, 87])\n",
      "torch.Size([1309, 140, 11])\n",
      "torch.Size([1309, 140, 11])\n"
     ]
    }
   ],
   "source": [
    "#print(x.shape)\n",
    "#print(y.shape)\n",
    "#print(mask.shape)\n",
    "#display(id_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_tensors_rnn_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_tensors_rnn_3d(data, target, is_synthetic = False):\n",
    "\n",
    "    #import libraries\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    from torch.nn.utils.rnn import pad_sequence\n",
    "    import torch.nn.functional as F\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    \n",
    "    if is_synthetic:\n",
    "        #tranform gamePlayId variable to account for synthetic data\n",
    "        # Create a mask to identify duplicates based on 'gamePlayId', 'frameId', and 'nflId'\n",
    "        duplicates_mask = data.duplicated(subset=['gamePlayId', 'frameId', 'nflId'], keep='first')\n",
    "\n",
    "        # Add '.1' to 'gamePlayId' for the second occurrence of each duplicate\n",
    "        data.loc[duplicates_mask, 'gamePlayId'] += '.1'\n",
    "        \n",
    "        \n",
    "    #Preprocess data correctly\n",
    "    target_variables = [\"tackle_binary_single\",\"tackle_binary_all\", \"tackle_nonbinary_all\", \"tackle_nonbinary_single\"]\n",
    "\n",
    "    #determine target variables to remove\n",
    "    target_variables.remove(target)\n",
    "\n",
    "    data = data.sort_values(['gameId','playId','nflId','frameId'],ascending = [True, True, True, True])\n",
    "\n",
    "    # remove unwanted variables \n",
    "    df = data.drop([\"gameId\",\"playId\"], axis = 1)\n",
    "    df = df.drop(target_variables, axis = 1)\n",
    "\n",
    "    # Separate numerical and categorical variables\n",
    "    numerical_vars = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_vars = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "    # Define variables to exclude\n",
    "    exclude_scaling = ['nflId', 'home', 'frameId'] #might need to change this depending on added variables\n",
    "    exclude_scaling.append(target)\n",
    "    exclude_ohe = ['gamePlayId']\n",
    "\n",
    "    # Scale numerical variables using StandardScaler, excluding variables\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_vars.difference(exclude_scaling)] = scaler.fit_transform(df[numerical_vars.difference(exclude_scaling)])\n",
    "\n",
    "    # One-hot encode categorical variables\n",
    "    df = pd.get_dummies(df, columns=categorical_vars.difference(exclude_ohe), drop_first=True)\n",
    "\n",
    "\n",
    "    ############################################################################################\n",
    "    #Group data into correct array format\n",
    "\n",
    "    # Group data by 'gamePlayId'\n",
    "    plays_grouped = df.groupby('gamePlayId')\n",
    "\n",
    "    # Determine the maximum number of frames per play and rows per frame\n",
    "    max_rows_per_frame = 140 #Max rows per per frame in our data is 140, so \n",
    "    num_feature_cols = df.shape[1] - 4 #number of columns - we are droping gamePlayId, frameId, nflId, and target\n",
    "\n",
    "    #Columns to drop in loop\n",
    "    cols_to_drop = ['gamePlayId', 'nflId','frameId', 'tackle_binary_single']\n",
    "\n",
    "    # Initialize lists for all plays' features, labels, and masks\n",
    "    all_player_features = []\n",
    "    all_player_labels = []\n",
    "    all_player_masks = []\n",
    "\n",
    "    # Initialize list to keep track of gameId, playId, nflId, frameId\n",
    "    gamePlayId_list = []\n",
    "    nflId_list = []\n",
    "    frameId_list = []\n",
    "\n",
    "    for play_id, play_data in plays_grouped:\n",
    "        # Group by 'frameId' within each play\n",
    "        players_grouped = play_data.groupby('nflId')\n",
    "\n",
    "        for player_id, player_data in players_grouped:\n",
    "            #drop grouping variables and target variable\n",
    "            features = player_data.drop(cols_to_drop, axis=1).values #remove the grouping variables\n",
    "            labels = player_data['tackle_binary_single'].values\n",
    "\n",
    "            # Extract the game, play, nflId, and frameId values for this player's data\n",
    "            gamePlayId = player_data['gamePlayId'].values[0]\n",
    "            nflId = player_data['nflId'].values[0]\n",
    "            frameId = player_data['frameId'].values[0]\n",
    "\n",
    "            # Calculate current frame length for the player\n",
    "            frame_length = len(features)\n",
    "\n",
    "            # Pad each player's features and labels to have the same number of rows\n",
    "            padded_features = np.pad(features, ((0, max_rows_per_frame - frame_length), (0, 0)), mode='constant', constant_values=0)\n",
    "            padded_labels = np.pad(labels, (0, max_rows_per_frame - frame_length), mode='constant', constant_values=0)\n",
    "\n",
    "            # Create mask for the current frame\n",
    "            mask = np.ones(max_rows_per_frame)\n",
    "            mask[:frame_length] = 1  # Actual data\n",
    "            mask[frame_length:] = 0  # Padded data\n",
    "\n",
    "            all_player_features.append(padded_features)\n",
    "            all_player_labels.append(padded_labels)\n",
    "            all_player_masks.append(mask)\n",
    "            gamePlayId_list.extend([gamePlayId] * max_rows_per_frame)\n",
    "            nflId_list.extend([nflId] * max_rows_per_frame)\n",
    "            frameId_list.extend([frameId + i for i in range(max_rows_per_frame)])\n",
    "\n",
    "\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    x = np.array(all_player_features, dtype=np.float32)\n",
    "    y = np.array(all_player_labels, dtype=np.int64)\n",
    "    mask_array = np.array(all_player_masks, dtype=np.int64)\n",
    "    id_data = pd.DataFrame({'gamePlayId': gamePlayId_list, 'nflId': nflId_list, 'frameId': frameId_list})\n",
    "\n",
    "    return torch.from_numpy(x), torch.from_numpy(y), torch.from_numpy(mask_array), id_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#train_samp = pd.read_csv(\"../Data/train_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, y, mask, id_data = data_tensors_rnn_3d(train_samp, \"tackle_binary_single\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x.shape)\n",
    "#print(y.shape)\n",
    "#print(mask.shape)\n",
    "#print(id_data.shape)\n",
    "#display(id_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accre/arch/easybuild/software/BinDist/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/accre/arch/easybuild/software/BinDist/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    }
   ],
   "source": [
    "# #import pandas as pd\n",
    "# train_samp = pd.read_csv(\"../Data/train_sample.csv\")\n",
    "# x, y, mask, id_data = data_tensors_cnn_4d(train_samp, \"tackle_binary_single\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1309, 140, 11, 87])\n",
      "torch.Size([1309, 140, 11])\n",
      "torch.Size([1309, 140, 11])\n",
      "(2015860, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamePlayId</th>\n",
       "      <th>nflId</th>\n",
       "      <th>frameId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022090800.01187.0</td>\n",
       "      <td>37075.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022090800.01187.0</td>\n",
       "      <td>37075.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022090800.01187.0</td>\n",
       "      <td>37075.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022090800.01187.0</td>\n",
       "      <td>37075.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022090800.01187.0</td>\n",
       "      <td>37075.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gamePlayId    nflId  frameId\n",
       "0  2022090800.01187.0  37075.0     19.0\n",
       "1  2022090800.01187.0  37075.0     20.0\n",
       "2  2022090800.01187.0  37075.0     21.0\n",
       "3  2022090800.01187.0  37075.0     22.0\n",
       "4  2022090800.01187.0  37075.0     23.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(x.shape)\n",
    "# print(y.shape)\n",
    "# print(mask.shape)\n",
    "# print(id_data.shape)\n",
    "# display(id_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
