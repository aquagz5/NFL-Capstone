{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7c2d71d-4f15-4b1c-83c4-1e270c12e01f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Model Preparation\n",
    "The following notebook contains the neccessary functions to prepare data into tensors for proper neural network use given the architecture of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93543ccc-ff7d-416e-b5d6-9a6685ec4feb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## data_tensors_cnn_4d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5636f88-db05-4cd2-96b3-f4b1e0351280",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The data_tensor_cnn_4d function performs the following operations on the data to prep for the model:\n",
    "1. Remove unwanted target variables, nflId, gameId, and playId\n",
    "2. Scale numerical data, excluding the gamePlayId, frameId, and binary values\n",
    "3. One-hot encode all categorical variables \n",
    "4. Group plays and frames into data \"images\" of player data on a given frame\n",
    "5. Pad arrays for consitent tensor datatypes \n",
    "6. Create mask array with a 1 to identify frames that were actual data and 0 to identify padded values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7934cd6-0090-4e3d-8e52-7ecf83b41c3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def data_tensors_cnn_4d(data, target, is_synthetic=False):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    from torch.nn.utils.rnn import pad_sequence\n",
    "    import torch.nn.functional as F\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    \n",
    "    if is_synthetic:\n",
    "        #tranform gamePlayId variable to account for synthetic data\n",
    "        # Create a mask to identify duplicates based on 'gamePlayId', 'frameId', and 'nflId'\n",
    "        duplicates_mask = data.duplicated(subset=['gamePlayId', 'frameId', 'nflId'], keep='first')\n",
    "\n",
    "        # Add '.1' to 'gamePlayId' for the second occurrence of each duplicate\n",
    "        data.loc[duplicates_mask, 'gamePlayId'] += '.1'\n",
    "\n",
    "    # Preprocess data correctly\n",
    "    # Target variables\n",
    "    target_variables = [\"tackle_binary_single\",\"tackle_binary_all\", \"tackle_nonbinary_all\", \"tackle_nonbinary_single\"]\n",
    "\n",
    "    # Determine target variables to remove\n",
    "    target_variables.remove(target)\n",
    "\n",
    "    # Remove unwanted variables \n",
    "    df = data.drop([\"gameId\",\"playId\",], axis=1)\n",
    "    df = df.drop(target_variables, axis=1)\n",
    "\n",
    "    # Separate numerical and categorical variables\n",
    "    numerical_vars = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_vars = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "    # Define variables to exclude\n",
    "    exclude_scaling = ['gameId', 'frameId','nflId', 'home'] # Might need to change this depending on added variables\n",
    "    exclude_scaling.append(target)\n",
    "    exclude_ohe = ['gamePlayId']\n",
    "\n",
    "    # Scale numerical variables using StandardScaler, excluding variables\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_vars.difference(exclude_scaling)] = scaler.fit_transform(df[numerical_vars.difference(exclude_scaling)])\n",
    "\n",
    "    # One-hot encode categorical variables\n",
    "    df = pd.get_dummies(df, columns=categorical_vars.difference(exclude_ohe), drop_first=True)\n",
    "\n",
    "    ############################################################################################\n",
    "    # Group data into correct array format\n",
    "\n",
    "    # Group data by 'gamePlayId'\n",
    "    plays_grouped = df.groupby('gamePlayId')\n",
    "\n",
    "    # Determine the maximum number of frames per play and rows per frame\n",
    "    max_frames_per_play = 140 # We found that the max number of frames per play in our data if 140\n",
    "    max_rows_per_frame = 11 # Set this to 11 players just a precaution, but all frames have all players on a given frame in our data\n",
    "    num_feature_cols = df.shape[1] - 4 # Number of columns - we are dropping gamePlayId, frameId, nflId and target\n",
    "\n",
    "    # Columns to drop in loop\n",
    "    cols_to_drop = ['gamePlayId', 'frameId','nflId', 'tackle_binary_single']\n",
    "\n",
    "    # Initialize lists for all plays' features, labels, and masks\n",
    "    all_play_features = []\n",
    "    all_play_labels = []\n",
    "    all_play_masks = []\n",
    "    gamePlayId_list = []\n",
    "    nflId_list = []\n",
    "    frameId_list = []\n",
    "\n",
    "    for play_id, play_data in plays_grouped:\n",
    "        # Group by 'frameId' within each play\n",
    "        frames_grouped = play_data.groupby('frameId')\n",
    "        \n",
    "        # Initialize lists for all frames within a play (features, labels, and masks)\n",
    "        play_features = []\n",
    "        play_labels = []\n",
    "        play_masks = []\n",
    "        play_gamePlayId_list = []\n",
    "        play_nflId_list = []\n",
    "        play_frameId_list = []\n",
    "\n",
    "        for frame_id, frame_data in frames_grouped:\n",
    "            # Drop grouping variables and target variable\n",
    "            features = frame_data.drop(cols_to_drop, axis=1).values # Remove the grouping variables\n",
    "            labels = frame_data['tackle_binary_single'].values\n",
    "\n",
    "            # Extract the game, play, nflId, and frameId values for this player's data\n",
    "            gamePlayId = frame_data['gamePlayId'].values[0]\n",
    "            nflId = frame_data['nflId'].values[0]\n",
    "            frameId = frame_data['frameId'].values[0]\n",
    "\n",
    "            # Calculate current frame length\n",
    "            frame_length = len(features)\n",
    "\n",
    "            # Pad each frame's features and labels to have the same number of rows\n",
    "            padded_features = np.pad(features, ((0, max_rows_per_frame - frame_length), (0, 0)), mode='constant', constant_values=0)\n",
    "            padded_labels = np.pad(labels, (0, max_rows_per_frame - frame_length), mode='constant', constant_values=0)\n",
    "            \n",
    "            # Create mask for the current frame\n",
    "            mask = np.ones(max_rows_per_frame)\n",
    "            mask[:frame_length] = 1  # Actual data\n",
    "            mask[frame_length:] = 0  # Padded data\n",
    "\n",
    "            play_features.append(padded_features)\n",
    "            play_labels.append(padded_labels)\n",
    "            play_masks.append(mask)\n",
    "            \n",
    "            # Extend the gameId, playId, nflId, and frameId lists\n",
    "            play_gamePlayId_list.extend([gamePlayId] * max_rows_per_frame)\n",
    "            play_nflId_list.extend([nflId] * max_rows_per_frame)\n",
    "            play_frameId_list.extend([frameId + i for i in range(max_rows_per_frame)])\n",
    "\n",
    "        frames_to_pad = max_frames_per_play - len(play_features)\n",
    "        play_features += [np.zeros((max_rows_per_frame, num_feature_cols)) for _ in range(frames_to_pad)]\n",
    "        play_labels += [np.zeros((max_rows_per_frame,)) for _ in range(frames_to_pad)]\n",
    "        play_masks += [np.zeros((max_rows_per_frame,)) for _ in range(frames_to_pad)]\n",
    "        \n",
    "        # Extend the ID lists for the padding frames\n",
    "        play_gamePlayId_list.extend([gamePlayId] * max_rows_per_frame * frames_to_pad)\n",
    "        play_nflId_list.extend([nflId] * max_rows_per_frame * frames_to_pad)\n",
    "        play_frameId_list.extend([frameId + max_rows_per_frame * i for i in range(frames_to_pad) for _ in range(max_rows_per_frame)])\n",
    "\n",
    "\n",
    "        all_play_features.append(play_features)\n",
    "        all_play_labels.append(play_labels)\n",
    "        all_play_masks.append(play_masks)\n",
    "        gamePlayId_list.extend(play_gamePlayId_list)\n",
    "        nflId_list.extend(play_nflId_list)\n",
    "        frameId_list.extend(play_frameId_list)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    x = np.array(all_play_features, dtype=np.float32)\n",
    "    y = np.array(all_play_labels, dtype=np.int64)\n",
    "    mask_array = np.array(all_play_masks, dtype=np.int64)\n",
    "\n",
    "    # Create a DataFrame to hold gameId, playId, nflId, and frameId values\n",
    "    id_data = pd.DataFrame({'gamePlayId': gamePlayId_list, 'nflId': nflId_list, 'frameId': frameId_list})\n",
    "\n",
    "    # Convert to PyTorch tensors and return them along with id_data\n",
    "    return torch.from_numpy(x), torch.from_numpy(y), torch.from_numpy(mask_array), id_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2156165-c5b7-4a2c-a8e5-ad347a5460a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#train_samp = pd.read_csv(\"../Data/train_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "437e2641-6751-4655-9428-cf61609d90c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#x, y, mask, id_data = data_tensors(train_samp, \"tackle_binary_single\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a14a4e7-e282-433a-9dc0-136a86c51fd5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#print(x.shape)\n",
    "#print(y.shape)\n",
    "#print(mask.shape)\n",
    "#display(id_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "023389fa-5d44-4eab-8a58-97a4c0de756e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## data_tensors_rnn_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4901b5c7-5eef-4f06-9dd3-bf49979b6511",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def data_tensors_rnn_3d(data, target, is_synthetic = False):\n",
    "\n",
    "    #import libraries\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    from torch.nn.utils.rnn import pad_sequence\n",
    "    import torch.nn.functional as F\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    \n",
    "    if is_synthetic:\n",
    "        #tranform gamePlayId variable to account for synthetic data\n",
    "        # Create a mask to identify duplicates based on 'gamePlayId', 'frameId', and 'nflId'\n",
    "        duplicates_mask = data.duplicated(subset=['gamePlayId', 'frameId', 'nflId'], keep='first')\n",
    "\n",
    "        # Add '.1' to 'gamePlayId' for the second occurrence of each duplicate\n",
    "        data.loc[duplicates_mask, 'gamePlayId'] += '.1'\n",
    "        \n",
    "        \n",
    "    #Preprocess data correctly\n",
    "    target_variables = [\"tackle_multiple\", \"tackle_single\"]\n",
    "\n",
    "    #determine target variables to remove\n",
    "    target_variables.remove(target)\n",
    "\n",
    "    data = data.sort_values(['gameId','playId','nflId','frameId'],ascending = [True, True, True, True])\n",
    "\n",
    "    # remove unwanted variables \n",
    "    df = data.drop([\"gameId\",\"playId\"], axis = 1)\n",
    "    df = df.drop(target_variables, axis = 1)\n",
    "\n",
    "    # Separate numerical and categorical variables\n",
    "    numerical_vars = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_vars = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "    # Define variables to exclude\n",
    "    exclude_scaling = ['nflId', 'home', 'frameId'] #might need to change this depending on added variables\n",
    "    exclude_scaling.append(target)\n",
    "    exclude_ohe = ['gamePlayId']\n",
    "\n",
    "    # Scale numerical variables using StandardScaler, excluding variables\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_vars.difference(exclude_scaling)] = scaler.fit_transform(df[numerical_vars.difference(exclude_scaling)])\n",
    "\n",
    "    # One-hot encode categorical variables\n",
    "    df = pd.get_dummies(df, columns=categorical_vars.difference(exclude_ohe), drop_first=True)\n",
    "\n",
    "\n",
    "    ############################################################################################\n",
    "    #Group data into correct array format\n",
    "\n",
    "    # Group data by 'gamePlayId'\n",
    "    plays_grouped = df.groupby('gamePlayId')\n",
    "\n",
    "    # Determine the maximum number of frames per play and rows per frame\n",
    "    max_rows_per_frame = 140 #Max rows per per frame in our data is 140, so \n",
    "    num_feature_cols = df.shape[1] - 4 #number of columns - we are droping gamePlayId, frameId, nflId, and target\n",
    "\n",
    "    #Columns to drop in loop\n",
    "    cols_to_drop = ['gamePlayId', 'nflId','frameId', 'tackle_single','tackle_multiple']\n",
    "\n",
    "    # Initialize lists for all plays' features, labels, and masks\n",
    "    all_player_features = []\n",
    "    all_player_labels = []\n",
    "    all_player_masks = []\n",
    "\n",
    "    # Initialize list to keep track of gameId, playId, nflId, frameId\n",
    "    gamePlayId_list = []\n",
    "    nflId_list = []\n",
    "    frameId_list = []\n",
    "\n",
    "    for play_id, play_data in plays_grouped:\n",
    "        # Group by 'frameId' within each play\n",
    "        players_grouped = play_data.groupby('nflId')\n",
    "\n",
    "        for player_id, player_data in players_grouped:\n",
    "            #drop grouping variables and target variable\n",
    "            features = player_data.drop(cols_to_drop, axis=1).values #remove the grouping variables\n",
    "            labels = player_data[target].values\n",
    "\n",
    "            # Extract the game, play, nflId, and frameId values for this player's data\n",
    "            gamePlayId = player_data['gamePlayId'].values[0]\n",
    "            nflId = player_data['nflId'].values[0]\n",
    "            frameId = player_data['frameId'].values[0]\n",
    "\n",
    "            # Calculate current frame length for the player\n",
    "            frame_length = len(features)\n",
    "\n",
    "            # Pad each player's features and labels to have the same number of rows\n",
    "            padded_features = np.pad(features, ((0, max_rows_per_frame - frame_length), (0, 0)), mode='constant', constant_values=0)\n",
    "            padded_labels = np.pad(labels, (0, max_rows_per_frame - frame_length), mode='constant', constant_values=0)\n",
    "\n",
    "            # Create mask for the current frame\n",
    "            mask = np.ones(max_rows_per_frame)\n",
    "            mask[:frame_length] = 1  # Actual data\n",
    "            mask[frame_length:] = 0  # Padded data\n",
    "\n",
    "            all_player_features.append(padded_features)\n",
    "            all_player_labels.append(padded_labels)\n",
    "            all_player_masks.append(mask)\n",
    "            gamePlayId_list.extend([gamePlayId] * max_rows_per_frame)\n",
    "            nflId_list.extend([nflId] * max_rows_per_frame)\n",
    "            frameId_list.extend([frameId + i for i in range(max_rows_per_frame)])\n",
    "\n",
    "\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    x = np.array(all_player_features, dtype=np.float32)\n",
    "    y = np.array(all_player_labels, dtype=np.int64)\n",
    "    mask_array = np.array(all_player_masks, dtype=np.int64)\n",
    "    id_data = pd.DataFrame({'gamePlayId': gamePlayId_list, 'nflId': nflId_list, 'frameId': frameId_list})\n",
    "\n",
    "    return torch.from_numpy(x), torch.from_numpy(y), torch.from_numpy(mask_array), id_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8d78ef5-1a85-458f-b569-dc070a97c5f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#train_samp = pd.read_csv(\"../Data/train_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0e4d90d-6c4a-45db-803b-068a3a31b0bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#x, y, mask, id_data = data_tensors_rnn_3d(train_samp, \"tackle_binary_single\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16a2ca18-d588-47c1-8136-80cb73c340b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#print(x.shape)\n",
    "#print(y.shape)\n",
    "#print(mask.shape)\n",
    "#print(id_data.shape)\n",
    "#display(id_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62e9d8fb-6aa1-4bf5-9a08-d99f3d369264",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# #import pandas as pd\n",
    "# train_samp = pd.read_csv(\"../Data/train_sample.csv\")\n",
    "# x, y, mask, id_data = data_tensors_cnn_4d(train_samp, \"tackle_binary_single\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32f508e6-57c6-405e-9d04-8cb431a1e8c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# print(x.shape)\n",
    "# print(y.shape)\n",
    "# print(mask.shape)\n",
    "# print(id_data.shape)\n",
    "# display(id_data.head())"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Model_prep",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
