{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b0b538",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "In this notebook, we generate new features to be used in the dataset for our models. We will include a feature name, description of the feature, justification for adding the feature, and a function to implement the feature for the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd053d64813ee2ff",
   "metadata": {},
   "source": [
    "## Features From Data\n",
    "\n",
    "The following features are variables from the data given to us from the kaggle competition that we believe to be valuable for our models: \n",
    "- From players.csv file:\n",
    "    - position: position of the player (character)\n",
    "    - weight: weight in lbs for defender (numeric)\n",
    "    - ballCarrier_position: position of ball carrier (character)\n",
    "    - weight_ballCarrier: weight in lbs for ball carrier (numeric)\n",
    "- From plays.csv file:\n",
    "    - passProbability: NGS probability of nex play being pass based on model, not the actually probability of pass being caught (numeric)\n",
    "    - preSnapWinProbabilityDefense: Win probability for visitor team (numeric)\n",
    "    - defendersInTheBox: Number of defenders in close proiximity to line-of-scrimmage (numeric)\n",
    "    - offenseFormation: Formation used by possession team (more on varibale down below) (character)\n",
    "    - absoluteYardlineNumber: Distnace from enzone for possession team (numeric)\n",
    "    - down: down of the play (numeric)\n",
    "    - yardsToGo: distance to get first down (numeric)\n",
    "- From tracking_week_#.csv files: \n",
    "    - x: player position along the long axis of the field (0-120 yards) (numeric)\n",
    "    - y: player position along the wide axis of the field (0 - 53.3 yards) (numeric)\n",
    "    - s: speed in yards/sec (numeric)\n",
    "    - a: speed in yards/sec^2 (numeric)\n",
    "    - o: player orientation (deg), 0-360 (numeric)\n",
    "    - dir: angle of player motion (deg), 0 - 360 degrees (numeric)\n",
    "    - football_x: football position along the long axis of the field (0-120 yards) (numeric) (not directly in data)\n",
    "    - football_y: football position along the wide axis of the field (0 - 53.3 yards) (numeric) (not directly in data)\n",
    "- From tackles.csv file: \n",
    "    - tackle: 0 or 1 indicating if the tackle was awarded (not direclty in data) (Dependent Variable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd228166e684b183",
   "metadata": {},
   "source": [
    "## Install External Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34973b56662f2c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:04.217687Z",
     "start_time": "2023-12-07T19:23:03.321030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: nfl_data_py in /Users/gmduncan/Library/Python/3.9/lib/python/site-packages (0.3.1)\r\n",
      "Requirement already satisfied: fastparquet>0.5 in /Users/gmduncan/Library/Python/3.9/lib/python/site-packages (from nfl_data_py) (2023.10.1)\r\n",
      "Requirement already satisfied: python-snappy>0.5 in /Users/gmduncan/Library/Python/3.9/lib/python/site-packages (from nfl_data_py) (0.6.1)\r\n",
      "Requirement already satisfied: pandas>1 in /Users/gmduncan/Library/Python/3.9/lib/python/site-packages (from nfl_data_py) (2.0.3)\r\n",
      "Requirement already satisfied: appdirs>1 in /Users/gmduncan/Library/Python/3.9/lib/python/site-packages (from nfl_data_py) (1.4.4)\r\n",
      "Requirement already satisfied: numpy>=1.20.3 in /Users/gmduncan/Library/Python/3.9/lib/python/site-packages (from fastparquet>0.5->nfl_data_py) (1.25.2)\r\n",
      "Requirement already satisfied: packaging in /Users/gmduncan/Library/Python/3.9/lib/python/site-packages (from fastparquet>0.5->nfl_data_py) (23.1)\r\n",
      "Requirement already satisfied: cramjam>=2.3 in /Users/gmduncan/Library/Python/3.9/lib/python/site-packages (from fastparquet>0.5->nfl_data_py) (2.7.0)\r\n",
      "Requirement already satisfied: fsspec in /Users/gmduncan/Library/Python/3.9/lib/python/site-packages (from fastparquet>0.5->nfl_data_py) (2023.10.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/gmduncan/Library/Python/3.9/lib/python/site-packages (from pandas>1->nfl_data_py) (2.8.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/gmduncan/Library/Python/3.9/lib/python/site-packages (from pandas>1->nfl_data_py) (2023.3)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/gmduncan/Library/Python/3.9/lib/python/site-packages (from pandas>1->nfl_data_py) (2023.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>1->nfl_data_py) (1.15.0)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\r\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nfl_data_py"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Remove tracking issues"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee9a6c348d857c32"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def remove_tracking_issues(tracking):\n",
    "    #plays to remove with players that have tracking anamolies that show up in the accleration\n",
    "    plays_to_rem = tracking[(tracking[\"displayName\"]!=\"football\") & (tracking[\"a\"]>17)][[\"gameId\",\"playId\"]].drop_duplicates()\n",
    "    \n",
    "    # Perform an anti-join on 'key' column\n",
    "    anti_join_result = tracking.merge(plays_to_rem, on=[\"gameId\",\"playId\"], how='left', indicator=True).query('_merge == \"left_only\"')\n",
    "\n",
    "    # Drop the '_merge' column used for indicator and reset index\n",
    "    anti_join_result = anti_join_result.drop('_merge', axis=1).reset_index(drop=True)\n",
    "\n",
    "    return anti_join_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:04.224609Z",
     "start_time": "2023-12-07T19:23:04.219260Z"
    }
   },
   "id": "56762e8bfd3c9cd0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Remove plays with multiple tackles"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59b93326c7179d2"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def remove_plays_with_mult_tackles(tracking,tackles):\n",
    "    duplicated_tackles = tackles[tackles[\"tackle\"]==1][[\"gameId\", \"playId\",\"nflId\"]].drop_duplicates()\n",
    "    plays_to_rem = duplicated_tackles[duplicated_tackles.duplicated(subset=['gameId', 'playId'], keep=False)][[\"gameId\", \"playId\"]]\n",
    "    \n",
    "    # Perform an anti-join on 'key' column\n",
    "    anti_join_result = tracking.merge(plays_to_rem, on=[\"gameId\",\"playId\"], how='left', indicator=True).query('_merge == \"left_only\"')\n",
    "\n",
    "    # Drop the '_merge' column used for indicator and reset index\n",
    "    anti_join_result = anti_join_result.drop('_merge', axis=1).reset_index(drop=True)\n",
    "    \n",
    "    return anti_join_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:04.224784Z",
     "start_time": "2023-12-07T19:23:04.221270Z"
    }
   },
   "id": "a44cad190ebc8a03"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Standardize field"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0351938f02e6c18"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def standardize_field(tracking):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # Applying the transformations\n",
    "    tracking['x'] = np.where(tracking['playDirection'] == 'left', 120 - tracking['x'], tracking['x'])\n",
    "    tracking['y'] = np.where(tracking['playDirection'] == 'left', 160/3 - tracking['y'], tracking['y'])\n",
    "    tracking['unitO'] = np.where(tracking['playDirection'] == 'left', (180 + tracking[\"unitO\"])%360, tracking['unitO'])\n",
    "    tracking['unitDir'] = np.where(tracking['playDirection'] == 'left',(180 + tracking[\"unitDir\"])%360 , tracking['unitDir'])\n",
    "\n",
    "    return tracking"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:04.230902Z",
     "start_time": "2023-12-07T19:23:04.226026Z"
    }
   },
   "id": "b58b502e3fcef068"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Filter frames by events"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8aab75ee1c48889"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def filter_frames_by_events(data):\n",
    "    # Define start and end events\n",
    "    start_events = ['run', 'handoff', 'pass_outcome_caught', 'lateral', 'snap_direct']\n",
    "    end_events = ['out_of_bounds', 'touchdown', 'fumble', 'qb_slide', 'tackle', 'safety']\n",
    "\n",
    "    # Function to filter frames for a single play\n",
    "    def filter_frames(play_data):\n",
    "        # Find the first frame of the start events\n",
    "        start_frame = play_data[play_data['event'].isin(start_events)]['frameId'].min()\n",
    "        \n",
    "        # Find the last frame before any of the end events\n",
    "        end_frame = play_data[play_data['event'].isin(end_events)]['frameId'].min()\n",
    "\n",
    "        # If start_frame or end_frame is NaN, return an empty DataFrame\n",
    "        if pd.isna(start_frame) or pd.isna(end_frame):\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Filter the play_data for frames between start_frame and end_frame\n",
    "        return play_data[(play_data['frameId'] >= start_frame) & (play_data['frameId'] <= end_frame)]\n",
    "\n",
    "    # Group by game and play, apply the filter_frames function, and concatenate the results\n",
    "    filtered_data = data.groupby(['gameId', 'playId']).apply(filter_frames)\n",
    "    \n",
    "    # Reset the index and return the result\n",
    "    return filtered_data.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:04.232028Z",
     "start_time": "2023-12-07T19:23:04.229321Z"
    }
   },
   "id": "54aef656e000ac4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Remove football frames"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34050492a4c8c3ab"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def remove_football_frames(tracking):\n",
    "\n",
    "    # Remove rows where 'football' is found in the specified column\n",
    "    filtered_data = tracking[tracking['displayName']!= \"football\"]\n",
    "\n",
    "    return filtered_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:04.358232Z",
     "start_time": "2023-12-07T19:23:04.350238Z"
    }
   },
   "id": "c5d4a80931eb79d3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculate voronoi tessellations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32986c4d505ae479"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def voronoi_tessellations(tracking, plays):\n",
    "    from scipy.spatial import Voronoi\n",
    "    from shapely.geometry import Point, Polygon\n",
    "    \n",
    "    tracking = tracking.merge(plays[['gameId', 'playId', 'ballCarrierId', 'defensiveTeam']], how = 'inner', on = ['gameId', 'playId'])\n",
    "    \n",
    "    def process_frame(df_frame):\n",
    "        # Sample DataFrame with columns: nflId, x, y, ballCarrierId\n",
    "        data = {\n",
    "            'gameId': df_frame['gameId'].values,\n",
    "            'playId': df_frame['playId'].values,\n",
    "            'frameId': df_frame['frameId'].values,\n",
    "            'nflId': df_frame['nflId'].values,\n",
    "            'x': df_frame['x'].values,\n",
    "            'y': df_frame['y'].values,\n",
    "            'ballCarrierId': df_frame['ballCarrierId'].iloc[0],\n",
    "            'club': df_frame['club'].values,\n",
    "            'defensiveTeam': df_frame['defensiveTeam'].values\n",
    "        }\n",
    "    \n",
    "        # Convert frame data to a Dataframe\n",
    "        df = pd.DataFrame(data)\n",
    "    \n",
    "        # Ghost records to add at corners of the field to help with infinite polygons\n",
    "        new_records = {\n",
    "            'gameId': 0,\n",
    "            'playId': 0,\n",
    "            'frameId': 0,\n",
    "            'nflId': [1, 2, 3, 4],\n",
    "            'x': [10.0, 10.0, 110.0, 110.0],\n",
    "            'y': [0.0, 53.3, 0.0, 53.3],\n",
    "            'ballCarrierId': df['ballCarrierId'].iloc[0],\n",
    "            'club': 'ghost',\n",
    "            'defensiveTeam': 'none'\n",
    "        }\n",
    "    \n",
    "        # Convert the new records to a DataFrame\n",
    "        new_df = pd.DataFrame(new_records)\n",
    "    \n",
    "        # Append the new DataFrame to the original DataFrame\n",
    "        df = pd.concat([df, new_df], ignore_index=True).dropna(subset=['nflId'])\n",
    "    \n",
    "        # Exclude the ball carrier from the player points\n",
    "        player_points_without_ball_carrier = df[df['nflId'] != df['ballCarrierId']][['x', 'y']].values\n",
    "    \n",
    "        # Compute Voronoi diagram for all non-ball carrier players\n",
    "        vor = Voronoi(player_points_without_ball_carrier)\n",
    "    \n",
    "        # Create a new column for the Voronoi region index for each non-ball carrier player\n",
    "        df['voronoi_region'] = -1  # Initialize with -1\n",
    "    \n",
    "        # Iterate through non-ball carrier players and Voronoi regions\n",
    "        for idx, (player, region_idx) in enumerate(zip(df[df['nflId'] != df['ballCarrierId']].itertuples(), vor.point_region)):\n",
    "            # Skip empty or incomplete regions\n",
    "            if region_idx != -1:\n",
    "                df.at[player.Index, 'voronoi_region'] = region_idx\n",
    "    \n",
    "        # Calculate the Voronoi region for the ball carrier\n",
    "        ball_carrier_point = df[df['nflId'] == df['ballCarrierId']][['x', 'y']].values[0]\n",
    "        ball_carrier_region = -1  # Initialize with -1\n",
    "    \n",
    "        # Create a dictionary to map nflId to voronoi_region\n",
    "        nflid_to_region = dict(zip(df['nflId'], df['voronoi_region']))\n",
    "    \n",
    "        # Iterate through Voronoi regions to find the one containing the ball carrier\n",
    "        for idx, region in enumerate(vor.regions):\n",
    "            if -1 not in region:\n",
    "                region_points = vor.vertices[region]\n",
    "                \n",
    "                # Reset point list to create next standardized polygon\n",
    "                region_points_standardized = []\n",
    "        \n",
    "                # Extract x and y coordinates from vertexes and limit values to dimensions of field\n",
    "                for vertex in region_points:\n",
    "                    vertex_point = Point(vertex)\n",
    "                    vertex_x, vertex_y = vertex_point.x, vertex_point.y\n",
    "                    vertex_x = 110 if vertex_x > 110 else (10 if vertex_x < 10 else vertex_x)\n",
    "                    vertex_y = 53.3 if vertex_y > 53.3 else (0 if vertex_y < 0 else vertex_y)\n",
    "                    vertex_point_standardized = Point(vertex_x, vertex_y)                \n",
    "                    region_points_standardized.append(vertex_point_standardized)\n",
    "                    \n",
    "                # Recreate polygon using standardized region points   \n",
    "                region_polygon = Polygon(region_points_standardized)\n",
    "                ball_carrier_point = Point(ball_carrier_point)\n",
    "                \n",
    "                # Initialize min and max distances for each iteration\n",
    "                min_dist_from_bc = float('inf')\n",
    "                \n",
    "                # Loop through nflId to identify who belongs to the current region\n",
    "                for nflid, region_value in nflid_to_region.items():\n",
    "                    if region_value == idx:\n",
    "    \n",
    "                        # Loop over all the points in the current region and identify minimum and maximum\n",
    "                        for vertex in region_points_standardized:\n",
    "                            vertex_point = Point(vertex)\n",
    "                            distance = ball_carrier_point.distance(vertex_point)\n",
    "                            min_dist_from_bc = min(min_dist_from_bc, distance)\n",
    "                            \n",
    "                        # Assign voronoi features for each player\n",
    "                        df.loc[df['nflId'] == nflid, 'voronoi_min_dist_from_bc'] = min_dist_from_bc\n",
    "    \n",
    "                # Identify if ball carrier is within this region\n",
    "                if ball_carrier_point.within(region_polygon):\n",
    "                    ball_carrier_region = idx\n",
    "    \n",
    "        # Create a new column to indicate (1/0) if the ball carrier is present in that Voronoi region\n",
    "        df['bc_in_voronoi'] = (df['voronoi_region'] == ball_carrier_region).astype(int)\n",
    "        \n",
    "        # Make min distance to ball carrier 0 if ball carrier is in region\n",
    "        df['voronoi_min_dist_from_bc'] = df.apply(lambda x: 0 if x['bc_in_voronoi'] else x['voronoi_min_dist_from_bc'], axis = 1)\n",
    "            \n",
    "        return df[['gameId','playId','frameId','nflId','voronoi_min_dist_from_bc']]\n",
    "    \n",
    "    # Assuming you have a DataFrame called 'tracking_data' with columns gameId, playId, and frameId\n",
    "    unique_game_play_frame = tracking[['gameId', 'playId', 'frameId']].drop_duplicates()\n",
    "    \n",
    "    \n",
    "    # Create an empty DataFrame to store results\n",
    "    result_df = pd.DataFrame()\n",
    "    \n",
    "    # Iterate over unique combinations of gameId, playId, frameId\n",
    "    for _, row in unique_game_play_frame.iterrows():\n",
    "        game_id, play_id, frame_id = row['gameId'], row['playId'], row['frameId']\n",
    "        \n",
    "        # Filter the original tracking data for the current combination\n",
    "        current_frame_data = tracking[(tracking['gameId'] == game_id) & (tracking['playId'] == play_id) & (tracking['frameId'] == frame_id)]\n",
    "        \n",
    "        # Process the frame and append the results to the result DataFrame\n",
    "        result_df = pd.concat([result_df, process_frame(current_frame_data)], ignore_index=True)\n",
    "        \n",
    "    return result_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af9ab8af1b340981"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Remove offensive players"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "100d79decc9de0ee"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def remove_offensive_players(tracking,plays):\n",
    "    data = tracking.merge(plays[[\"gameId\",\"playId\",\"defensiveTeam\"]], how = \"inner\", on = [\"gameId\",\"playId\"])\n",
    "    return data[data[\"club\"]==data[\"defensiveTeam\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:04.533448Z",
     "start_time": "2023-12-07T19:23:04.518550Z"
    }
   },
   "id": "721604e1be91a9f3"
  },
  {
   "cell_type": "markdown",
   "id": "a14709b3",
   "metadata": {},
   "source": [
    "# Orient Angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c807a6ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:04.694082Z",
     "start_time": "2023-12-07T19:23:04.685389Z"
    }
   },
   "outputs": [],
   "source": [
    "def orient_angle(angle):\n",
    "    if angle >=0 and angle < 90:\n",
    "        return (90-angle)\n",
    "    if angle >=90 and angle <180:\n",
    "        return ((180-angle)+270)\n",
    "    if angle >=180 and angle < 270:\n",
    "        return ((270 -angle)+180)\n",
    "    else:\n",
    "        return(180-(angle - 270))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97109636",
   "metadata": {},
   "source": [
    "## Distance Between Players and Projections Between Players\n",
    "This will calculate the distance between each player and the other players on the field, based on position, as well as the distance between the player and the football."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cb50f403c5317da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:04.867890Z",
     "start_time": "2023-12-07T19:23:04.857718Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_angle(x_defender, y_defender, x_ball_carrier, y_ball_carrier, defender_dir):\n",
    "    import math\n",
    "    \n",
    "    delta_x = x_ball_carrier - x_defender\n",
    "    delta_y = y_ball_carrier - y_defender\n",
    "    # Calculate the angle in radians\n",
    "    angle_radians = np.arctan2(delta_y, delta_x)\n",
    "    \n",
    "    # Convert the angle to degrees and ensure it's within the [0, 360) range\n",
    "    angle_degrees = (np.degrees(angle_radians))\n",
    "    \n",
    "    if (angle_degrees < 0).all():\n",
    "        angle_degrees = 360 - abs(angle_degrees)\n",
    "    \n",
    "    #How far away is the angle of the player from the trajectory\n",
    "    angle_degrees = abs(defender_dir - angle_degrees)\n",
    "    \n",
    "    \n",
    "    #Orient angle correctly for player\n",
    "    if (angle_degrees > 180).all():\n",
    "        angle_degrees = 360 - angle_degrees\n",
    "    \n",
    "    return angle_degrees\n",
    "\n",
    "# Define a function to calculate distance\n",
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    from math import sqrt\n",
    "    return sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caafb1b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:04.953230Z",
     "start_time": "2023-12-07T19:23:04.943572Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_distance_angles(tracking, plays):\n",
    "    import math\n",
    "    # Merge tracking data with plays data and the columns needed to identify defensive team and ballcarrier\n",
    "    data = tracking.merge(plays[[\"gameId\",\"playId\",\"defensiveTeam\",\"ballCarrierId\"]], how=\"inner\", on=[\"gameId\",\"playId\"])\n",
    "\n",
    "    # Prepare columns for distances (c1Dist, c2Dist, ..., c10Dist)\n",
    "    for i in range(1, 11):\n",
    "        data[f'c{i}Dist'] = None\n",
    "\n",
    "    # Prepare columns for projection (c1Proj, c2Proj, ..., c10Proj)\n",
    "    for i in range(1, 11):\n",
    "        data[f'c{i}Ang'] = None\n",
    "\n",
    "    # Prepare columns for ball carrier distance and Projection\n",
    "    data[\"bcDist\"] = None\n",
    "    data[\"bcAng\"] = None\n",
    "\n",
    "    # Process each game, play, and frame\n",
    "    for (game_id, play_id), play_data in data.groupby(['gameId', 'playId']):\n",
    "        # Determine the defensive team for this play\n",
    "        defensive_team = play_data.iloc[0]['defensiveTeam']\n",
    "        ballCarrierId = play_data.iloc[0]['ballCarrierId']\n",
    "\n",
    "        for frame_id, frame_data in play_data.groupby('frameId'):\n",
    "            # Separate defensive and offensive players\n",
    "            defensive_players = frame_data[frame_data['club'] == defensive_team]\n",
    "            offensive_players = frame_data[(frame_data['club'] != defensive_team) & (frame_data['displayName'] != \"football\")]\n",
    "\n",
    "            for index, def_player in defensive_players.iterrows():\n",
    "                # Calculate distances to all offensive players except the ball carrier\n",
    "                distances_angles = [\n",
    "                    (calculate_distance(def_player['x'], def_player['y'], off_player['x'], off_player['y']),\n",
    "                     calculate_angle(def_player['x'], def_player['y'], off_player['x'], off_player['y'], def_player[\"unitDir\"]))\n",
    "                    for _, off_player in offensive_players.iterrows()\n",
    "                    if off_player['nflId'] != ballCarrierId\n",
    "                ]\n",
    "\n",
    "                # Sort distances_projections by distances in ascending order\n",
    "                distances_angles.sort(key=lambda x: x[0])\n",
    "\n",
    "                # Update the DataFrame with sorted distances and projections\n",
    "                for i, (dist, angle) in enumerate(distances_angles[:10], start=1):\n",
    "                    data.loc[index, f'c{i}Dist'] = dist\n",
    "                    data.loc[index, f'c{i}Ang'] = angle\n",
    "\n",
    "                # Update the DataFrame with ball carrier distance and Projection\n",
    "                bc_dist = calculate_distance(def_player['x'], def_player['y'],\n",
    "                                   offensive_players[offensive_players[\"nflId\"] == ballCarrierId]['x'],\n",
    "                                   offensive_players[offensive_players[\"nflId\"] == ballCarrierId]['y'])\n",
    "                bc_angle = calculate_angle(def_player['x'], def_player['y'],\n",
    "                             offensive_players[offensive_players[\"nflId\"] == ballCarrierId]['x'],\n",
    "                             offensive_players[offensive_players[\"nflId\"] == ballCarrierId]['y'],\n",
    "                             def_player[\"unitDir\"])\n",
    "                data.loc[index, 'bcDist'] = bc_dist\n",
    "                data.loc[index, 'bcAng'] = float(bc_angle.iloc[0])\n",
    "\n",
    "    return data[[\"gameId\", \"playId\", \"nflId\", \"frameId\",\n",
    "                 \"c1Dist\", \"c2Dist\", \"c3Dist\", \"c4Dist\", \"c5Dist\", \"c6Dist\", \"c7Dist\", \"c8Dist\", \"c9Dist\", \"c10Dist\", \"bcDist\",\n",
    "                 \"c1Ang\", \"c2Ang\", \"c3Ang\", \"c4Ang\", \"c5Ang\", \"c6Ang\", \"c7Ang\", \"c8Ang\", \"c9Ang\", \"c10Ang\", \"bcAng\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe15401a39b3879",
   "metadata": {},
   "source": [
    "## Game Tackling Metrics\n",
    "This will create in game tackling metrics for the defensive players. Each player will have their total tackles and assists, tackles, assists, missed tackles, and forced fumbles assigned to them in the dataframe for the cumulative plays that have occurred up to that point in the game. A tackle efficiency metric will also be calculated which represents the percent of time a player made a tackle when they had the opportunity to do so. Lastly, a rough version of a tackle rating has been calculated, building on the tackle efficiency metric. This will assign weights to each type of tackle metric, for example, a forced fumble will be weighted much heavier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1afa27d70207f71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:05.115921Z",
     "start_time": "2023-12-07T19:23:05.103818Z"
    }
   },
   "outputs": [],
   "source": [
    "def ingame_tackling(df_week):\n",
    "    \n",
    "    def ingame_stats(row, tackles):\n",
    "        game_id = row['gameId']\n",
    "        play_id = row['playId']\n",
    "        nfl_id = row['nflId']\n",
    "        \n",
    "        # For the gameId and nflId, get cumulative values for tackling metrics up until that play in the gme\n",
    "        cumulative_tackling = tackles[(tackles['gameId'] == game_id) & (tackles['nflId'] == nfl_id) & (tackles['playId'] < play_id)][['tackle', 'assist', 'forcedFumble', 'pff_missedTackle']].sum()\n",
    "        return cumulative_tackling['tackle'], cumulative_tackling['assist'], cumulative_tackling['forcedFumble'], cumulative_tackling['pff_missedTackle']\n",
    "    \n",
    "    # Only apply above function for the minimum frame to speed up processing\n",
    "    min_frame_indices = df_week.groupby(['gameId', 'playId', 'nflId'])['frameId'].idxmin()\n",
    "    min_frame_data = df_week.loc[min_frame_indices]\n",
    "\n",
    "    # Apply the function to the week dataframe and rename the columns\n",
    "    cumulative_stats = min_frame_data.apply(lambda row: ingame_stats(row, tackles), axis = 1, result_type='expand')\n",
    "    cumulative_stats.columns = ['tackles_ingame', 'assists_ingame', 'ff_ingame', 'misses_ingame']\n",
    "    \n",
    "    # Create other in game metrics\n",
    "    cumulative_stats['tackle_efficiency_ingame'] = (cumulative_stats['tackles_ingame'] + cumulative_stats['assists_ingame']) / (cumulative_stats['tackles_ingame'] + cumulative_stats['assists_ingame'] + cumulative_stats['misses_ingame'])\n",
    "    \n",
    "    # Create a weighted tackle rating for in game stats\n",
    "    cumulative_stats['tackle_rating_ingame'] = (cumulative_stats['tackles_ingame'] + cumulative_stats['assists_ingame'] * .5 + cumulative_stats['ff_ingame'] * 5) / (cumulative_stats['tackles_ingame'] + cumulative_stats['assists_ingame'] + cumulative_stats['misses_ingame'])\n",
    "    \n",
    "    # Concatenate cumulative game results with gameId, playId, and nflId\n",
    "    cumulative_stats = pd.concat([min_frame_data[['gameId', 'playId', 'nflId']], cumulative_stats], axis = 1) \n",
    "    \n",
    "    # Fill nan in as 0\n",
    "    cumulative_stats['tackle_efficiency_ingame'].fillna(0, inplace=True)\n",
    "    cumulative_stats['tackle_rating_ingame'].fillna(0, inplace=True)\n",
    "    \n",
    "    return cumulative_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df46ead17b04ab6",
   "metadata": {},
   "source": [
    "## Rolling Tackling Metrics\n",
    "This will create rolling tackle metrics for the defensive players last 3 weeks. Each player will have their total tackles and assists, tackles, assists, missed tackles, and forced fumbles assigned to them in the dataframe. A tackle efficiency metric will also be calculated which represents the percent of time a player made a tackle when they had the opportunity to do so. Lastly, a rough version of a tackle rating has been calculated, building on the tackle efficiency metric. This will assign weights to each type of tackle metric, for example, a forced fumble will be weighted much heavier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d59c2f5a62ea85b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:05.274843Z",
     "start_time": "2023-12-07T19:23:05.267910Z"
    }
   },
   "outputs": [],
   "source": [
    "def rolling_tackling():\n",
    "  \n",
    "    # Subset and merge the games and tackles data\n",
    "    g = games[['gameId', 'week']]\n",
    "    tackle_history = g.merge(tackles, how = 'left', on = 'gameId')\n",
    "    \n",
    "    tackles_weekly = tackle_history.groupby(['week', 'gameId', 'nflId'])[['tackle', 'assist', 'forcedFumble', 'pff_missedTackle']].sum().reset_index()\n",
    "    \n",
    "    def rolling_sums(row, window_size = 3):\n",
    "        # Sort values by week to ensure the rolling window follows chronological order\n",
    "        row = row.sort_values('week')\n",
    "        \n",
    "        # Calculate the rolling sums\n",
    "        row['rolling_tackles'] = row['tackle'].rolling(window = window_size, min_periods = 1).sum().shift()\n",
    "        row['rolling_assists'] = row['assist'].rolling(window = window_size, min_periods = 1).sum().shift()\n",
    "        row['rolling_ff'] = row['forcedFumble'].rolling(window = window_size, min_periods = 1).sum().shift()\n",
    "        row['rolling_mt'] = row['pff_missedTackle'].rolling(window = window_size, min_periods = 1).sum().shift()\n",
    "        \n",
    "        return row\n",
    "    \n",
    "    # Group by nflId without prepending group keys to the result index\n",
    "    df_rolling = tackles_weekly.groupby('nflId', group_keys = False).apply(rolling_sums)\n",
    "    df_rolling = df_rolling[['gameId', 'nflId', 'rolling_tackles', 'rolling_assists', 'rolling_ff', 'rolling_mt']].fillna(0)\n",
    "    \n",
    "    return df_rolling"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Game Misc Attributes\n",
    "\n",
    "From dataset, bring in information such as surface the game was played on, and if it was inside or outside"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95c897e3f192a6dd"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2303a9649d9e8677",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:05.443981Z",
     "start_time": "2023-12-07T19:23:05.436034Z"
    }
   },
   "outputs": [],
   "source": [
    "# game_misc: function to obtain \n",
    "# input: shorten binary variable to collopse different types of turn into only categorical variable\n",
    "# output: dataframe of gamedata with gameId, categorical surface type, and categorical variable for indoor/outdoor\n",
    "# games.merge(game_miscs(), on = \"gameId\", how = \"left\")\n",
    "def game_miscs():\n",
    "    import nfl_data_py as nfl\n",
    "\n",
    "    # Import data and get only relevant columns\n",
    "    df_2022 = nfl.import_pbp_data([2022])\n",
    "    df_2022 = df_2022[['home_team', 'away_team', 'week', 'roof', 'surface']].drop_duplicates()\n",
    "    \n",
    "    # Join onto games dataset to combine with information we imported\n",
    "    games_misc = games.merge(df_2022, how = 'inner', left_on = ['week', 'homeTeamAbbr', 'visitorTeamAbbr'], right_on = ['week', 'home_team', 'away_team'])\n",
    "    \n",
    "    # Transform roof variable to inside or outside and get relevant columns \n",
    "    games_misc['inside_outside'] = games_misc.apply(lambda x: 'inside' if x['roof'] in ['dome', 'closed'] else 'outside', axis = 1)\n",
    "    games_misc = games_misc[['gameId', 'surface', 'inside_outside']]\n",
    "    \n",
    "    #Change this so all turf surfaces become turf and anything empty becomes grass \n",
    "    games_misc['surface'] = games_misc['surface'].apply(lambda x: 'turf' if 'turf' in x else 'grass')\n",
    "    \n",
    "    return games_misc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfbd535",
   "metadata": {},
   "source": [
    "# Play Types\n",
    "\n",
    "The play_type variable identifies what type of play occurs on a given play: pass, run, qb_run (designed or scramble), or other. In the data-investigation.ipynb notebook, we identified that all our passes in the data were caught by an offensive player. Anytime within the tracking data, a play was labeled with the event of \"pass_outcome_caught, \"lateral\", or \"autoevent_passforward\". We also identified that all plays that had a tracking event with \"handoff\" were designed runs by someone other than the player who obtained the snap. While, \"run\" was identified as those plays that the player who obtained the snapped ball (most of the time a QB) either scrambled or had a designed run. We labeled these as \"qb_run\". Lastly, if there were any other plays that did not have these tracking events, we labeled these as \"Other\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7cf2136",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:05.616863Z",
     "start_time": "2023-12-07T19:23:05.603631Z"
    }
   },
   "outputs": [],
   "source": [
    "# play_type: takes the plays and tracking data to obtain a data frame with a unique identifier for a given play\n",
    "#            and the type of play that was ran on that play\n",
    "# input: plays and tracking dataframes\n",
    "# output: data frame with \"gameId\", \"playId\", \"play_type\"\n",
    "# usage: tracking.merge(play_type(plays,tracking), on = [\"GameId\",\"PlayId\"])\n",
    "def play_type(plays,tracking):\n",
    "    # Create a function to determine play type\n",
    "    def determine_play_type(play_data):\n",
    "        if any(np.isin(play_data[\"event\"].values, [\"pass_outcome_caught\", \"lateral\", \"autoevent_passforward\"])):\n",
    "            return \"pass\"\n",
    "        elif \"handoff\" in play_data[\"event\"].values:\n",
    "            return \"run\"\n",
    "        elif \"run\" in play_data[\"event\"].values:\n",
    "            return \"qb_run\"\n",
    "        else:\n",
    "            return \"other\"\n",
    "        \n",
    "        \n",
    "    plays_tracking = plays.merge(tracking, on = [\"gameId\", \"playId\"])\n",
    "    #Drop duplicates, just need gameId,playId,frameId, event, ball_carrier position\n",
    "    bc_event = plays_tracking[plays_tracking[\"event\"].notna()][['gameId', 'playId', 'frameId', 'event']].drop_duplicates().reset_index(drop=True)\n",
    "    # Group by 'gameId' and 'playId' and apply the function to each group\n",
    "    result = bc_event.groupby(['gameId', 'playId']).apply(determine_play_type).reset_index()\n",
    "    result.columns = ['gameId', 'playId', 'play_type']\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae68d5e",
   "metadata": {},
   "source": [
    "# Defense Formations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "407f6b2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:05.775770Z",
     "start_time": "2023-12-07T19:23:05.769984Z"
    }
   },
   "outputs": [],
   "source": [
    "# defense_formation: Takes a play and counts the number of dlineman, linebackers, and dbacks on a given play based on the \n",
    "#                    position categorized for the player\n",
    "# Input: plays, tackles, tracking, players data\n",
    "# Output: data frame with \"gameId\", \"playId\",\"DL\", \"LB\",\"DB\" and the corresponsing counts on the play\n",
    "# Usage: tracking.merge(defense_formation(plays,tackles, tracking,players), on = [\"gameId\", \"playId\"])\n",
    "def defense_formation(plays,tackles, tracking,players):\n",
    "    \n",
    "    dlinemen = ['DT','DE']\n",
    "    linebackers = ['OLB','ILB','MLB', 'RB']\n",
    "    dbacks = ['CB','FS', 'SS', 'NT', 'DB', 'WR']\n",
    "\n",
    "    # Categorize defenders \n",
    "    def defense_pos(pos):\n",
    "        if pos in dlinemen:\n",
    "            return 'DL'\n",
    "        elif pos in linebackers:\n",
    "            return 'LB'\n",
    "        elif pos in dbacks:\n",
    "            return 'DB'\n",
    "\n",
    "    def count_positions(play):\n",
    "\n",
    "        counts = play['positionCat'].value_counts()\n",
    "        dl = counts.get('DL', 0)\n",
    "        lb = counts.get('LB', 0)\n",
    "        db = counts.get('DB', 0)\n",
    "\n",
    "        # Create the defense formation string\n",
    "        defense_formation = f\"{dl} - {lb} - {db}\"\n",
    "\n",
    "        return pd.Series({\n",
    "            'DL': dl,\n",
    "            'LB': lb,\n",
    "            'DB': db,\n",
    "            'defFormation': defense_formation\n",
    "        })\n",
    "    \n",
    "    # Subset the datasets \n",
    "    plays_sub = plays[['gameId','playId','defensiveTeam','playDescription']]\n",
    "    tackles_sub = tackles[['gameId','playId','nflId','tackle','assist']]\n",
    "    tracking_sub = tracking[['gameId','playId','nflId','displayName','club']]\n",
    "    players_sub = players[['nflId','displayName','position']]\n",
    "\n",
    "    # Merge the Datasets\n",
    "    inter = plays_sub.merge(tracking_sub, how='inner', on=['gameId','playId'])\n",
    "    df = inter.merge(players_sub, how='left', on=['nflId'])\n",
    "\n",
    "    # Filter for defense only \n",
    "    defense = df[df['club'] == df['defensiveTeam']].drop_duplicates()\n",
    "    \n",
    "    defense['positionCat'] = defense['position'].apply(defense_pos)\n",
    "\n",
    "    #Apply the function to each group\n",
    "    position_counts = defense.groupby(['gameId', 'playId']).apply(count_positions).reset_index()\n",
    "\n",
    "    # # Merge the position counts back into the df DataFrame\n",
    "    new_df = df.merge(position_counts, on=['gameId', 'playId'], how='left')\n",
    "    \n",
    "    return new_df[[\"gameId\", \"playId\",\"DL\", \"LB\",\"DB\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1beb161",
   "metadata": {},
   "source": [
    "# Offense Formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e204daf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:05.950909Z",
     "start_time": "2023-12-07T19:23:05.939171Z"
    }
   },
   "outputs": [],
   "source": [
    "# offense_formation: Takes a play and counts the number of WR, QB, TE, RB, OL on a given play based on the \n",
    "#                    position categorized for the player\n",
    "# Input: plays, tackles, tracking, players data\n",
    "# Output: data frame with \"gameId\", \"playId\",\"WR\", \"QB\",\"TE\", \"RB\", \"OL\" and the corresponsing counts on the play\n",
    "# Usage: tracking.merge(defense_formation(plays,tackles, tracking,players), on = [\"gameId\", \"playId\"])\n",
    "def offense_formation(plays,tackles, tracking,players):\n",
    "    \n",
    "    QB = ['QB']\n",
    "    RB = [\"RB\",\"FB\"]\n",
    "    WR = [\"WR\"]\n",
    "    TE = [\"TE\"]\n",
    "    OL = [\"G\", \"C\", \"T\",\"ILB\", \"OLB\", \"MLB\", \"DT\"]\n",
    "\n",
    "    # Categorize defenders \n",
    "    def defense_pos(pos):\n",
    "        if pos in RB:\n",
    "            return 'RB'\n",
    "        elif pos in OL:\n",
    "            return 'OL'\n",
    "        else:\n",
    "            return pos\n",
    "\n",
    "    def count_positions(play):\n",
    "\n",
    "        counts = play['positionCat'].value_counts()\n",
    "        Qb = counts.get('QB', 0)\n",
    "        Rb = counts.get('RB', 0)\n",
    "        Wr = counts.get('WR', 0)\n",
    "        Te = counts.get('TE', 0)\n",
    "        Ol = counts.get('OL', 0)\n",
    "\n",
    "\n",
    "        return pd.Series({\n",
    "            'QB': Qb,\n",
    "            'RB': Rb,\n",
    "            'WR': Wr,\n",
    "            'TE': Te,\n",
    "            'OL': Ol\n",
    "        })\n",
    "    \n",
    "    # Subset the datasets \n",
    "    plays_sub = plays[['gameId','playId','possessionTeam','playDescription']]\n",
    "    tackles_sub = tackles[['gameId','playId','nflId','tackle','assist']]\n",
    "    tracking_sub = tracking[['gameId','playId','nflId','displayName','club']]\n",
    "    players_sub = players[['nflId','displayName','position']]\n",
    "\n",
    "    # Merge the Datasets\n",
    "    inter = plays_sub.merge(tracking_sub, how='inner', on=['gameId','playId'])\n",
    "    df = inter.merge(players_sub, how='left', on=['nflId'])\n",
    "\n",
    "    # Filter for defense only \n",
    "    offense = df[df['club'] == df['possessionTeam']].drop_duplicates()\n",
    "    \n",
    "    offense['positionCat'] = offense['position'].apply(defense_pos)\n",
    "\n",
    "    #Apply the function to each group\n",
    "    position_counts = offense.groupby(['gameId', 'playId']).apply(count_positions).reset_index()\n",
    "\n",
    "    # # Merge the position counts back into the df DataFrame\n",
    "    new_df = df.merge(position_counts, on=['gameId', 'playId'], how='left')\n",
    "    \n",
    "    return new_df[[\"gameId\", \"playId\",\"QB\", \"RB\",\"WR\", \"TE\", \"OL\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7540e9",
   "metadata": {},
   "source": [
    "# Game Time in Seconds\n",
    "\n",
    "The purpose of this function is to calculate the number of seconds since the start of the game. Hence, we should have 0 seconds for the first play of the game if the play started at 15:00 in Q1. At 15:00 in Q2, we will have 900 seconds. At 15:00 in Q3, we will have 1800 seconds. At 15:00 in Q4, we will have 2700 seconds. At 0:00 in the Q4, we will have 3600 seconds. Lastly for 10:00 at 10:00, we will have 3600 seconds and a max value of 4200 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bb521f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:06.109391Z",
     "start_time": "2023-12-07T19:23:06.102280Z"
    }
   },
   "outputs": [],
   "source": [
    "# nfl_clock_to_seconds: takes a row of data and changes the game clock with its quarter to a corresponding time value \n",
    "#                       in seconds from the start of the game, i.e. 0 seconds at the start, and 3600 at the end of Q4\n",
    "# input: row of data\n",
    "# output: computed total seconds from the start of the game given the gameClock and quarter variable from plays data\n",
    "# usage: plays[\"timeSinceStart\"] = plays.apply(nfl_clock_to_seconds,axis = 1)\n",
    "def nfl_clock_to_seconds(row):\n",
    "    # Convert quarter to minutes\n",
    "    if row[\"quarter\"] == 1:\n",
    "        quarter_minutes = 0\n",
    "    elif row[\"quarter\"] == 2:\n",
    "        quarter_minutes = 15\n",
    "    elif row[\"quarter\"] == 3:\n",
    "        quarter_minutes = 30\n",
    "    elif row[\"quarter\"] == 4:\n",
    "        quarter_minutes = 45\n",
    "    elif row[\"quarter\"] == 5:\n",
    "        quarter_minutes = 60\n",
    "\n",
    "    # Split the clock into minutes and seconds\n",
    "    clock_parts = row[\"gameClock\"].split(\":\")\n",
    "\n",
    "    minutes = int(clock_parts[0])\n",
    "    seconds = int(clock_parts[1])\n",
    "\n",
    "    # Calculate the total time in seconds\n",
    "    if row[\"quarter\"]!=5:\n",
    "        total_seconds = quarter_minutes*60 + (900- (minutes*60 + seconds))\n",
    "    else:\n",
    "        total_seconds = quarter_minutes*60 + (600- (minutes*60 + seconds))\n",
    "\n",
    "    return total_seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d555d5cfd3d87d",
   "metadata": {},
   "source": [
    "# presnapDefenseWinProbability and home\n",
    "\n",
    "The following function will take the tracking, games, and plays data and return the features presnapeDefenseProbabiity and home variable. This feature will calculate the win probability in terms of the defense rather than home vs away. It will also include a binary variable for whether the player on the team is playing on the home team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc637f9bc0062d1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:06.277296Z",
     "start_time": "2023-12-07T19:23:06.270269Z"
    }
   },
   "outputs": [],
   "source": [
    "# presnapDefenseWinProbability: takes plays, tracking, and plays to calculate the presnapDefenseWinProbability and identfiy\n",
    "#                               whether the player is playing for the home team\n",
    "# input: games, tracking, plays\n",
    "# output: a dataframe of gameId, playId, nflId, frameId, home binary variable, preSnapWinProbabilityDefense\n",
    "# usage: tracking.merge(presnapDefenseWinProbability(games, tracking, plays), on = [\"gameId\", \"playId\", \"nflId\", \"frameId\"])\n",
    "def presnapDefenseWinProbability(games, tracking, plays):\n",
    "    merged = pd.merge(games, plays, on = 'gameId', how = 'inner') #merge games and plays\n",
    "    merged = pd.merge(merged, tracking, on = ['gameId','playId'], how = 'inner') #merge games, plays, tracking\n",
    "\n",
    "    #need to know who the club of the player is, preSnapHomeTeamWinProability, who the home team is and whos on defense\n",
    "    #create home variable if club is home team\n",
    "    merged[\"home\"]=(merged[\"club\"]== merged[\"homeTeamAbbr\"]).astype(int)\n",
    "    #create preSnapWInProbabilityDefense variable if homeTeamAbbr == defensiveTeam then use home team win prob, else use 1 - home team win prob\n",
    "    merged[\"preSnapWinProbabilityDefense\"] = merged.\\\n",
    "                apply(lambda row: row['preSnapHomeTeamWinProbability'] if row[\"homeTeamAbbr\"]==row[\"defensiveTeam\"] else\n",
    "                     1 - row['preSnapHomeTeamWinProbability'], axis = 1)\n",
    "\n",
    "    #return gameId, playId, nflId home, preSnapWinProbabilityDefense to merge for feature\n",
    "    return merged[[\"gameId\",\"playId\",\"nflId\",\"frameId\",\"home\",\"preSnapWinProbabilityDefense\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a4f7e5bee5c01e",
   "metadata": {},
   "source": [
    "# Dependent variable: Tackle\n",
    "\n",
    "For the dependent variable, we are going to create four different possible variables so that we can decide later what we want to do. 1. a 0/1 to the player who made a tackle throughout the entire play 2. a 0/.5/1 to the player who made a tackle throughout the entire play 3. a 0/1 to the player who made the tackle at the exact moment 4. 0/.5/1 to the player who made the tackle at the exact moment. This way we have everything we need on the decision we want to take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7cb7374e0b3ec24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:06.449376Z",
     "start_time": "2023-12-07T19:23:06.438366Z"
    }
   },
   "outputs": [],
   "source": [
    "#Function to obtain appropriate dependent variable\n",
    "#Input: tackles, tracking data\n",
    "#Output: data frame with gameId, playId, frameId, nflId, tackle_binary_all, tackle_binary_singl, tackle_nonbinary_all, tackle_nonbinary_single\n",
    "def tackle_dependent_variable(tackles,tracking):\n",
    "    \n",
    "    #merge tracking and tackles\n",
    "    merged = pd.merge(tracking, tackles, on = ['gameId','playId', 'nflId'], how = 'left')   \n",
    "    \n",
    "    #create a new variable called tackle_binary_all for the player who made the tackle or assist on a given play to have a value of 1 and 0 otherwise\n",
    "    merged[\"tackle_binary_all\"] = merged.apply(lambda row: 1 if row['tackle'] == 1 or row['assist'] == 1 else 0, axis=1)\n",
    "    print(\"done tackle_binary_all\")\n",
    "\n",
    "    #create a new variable called tackle_binary_single for the player who made the tackle on at the instance they made the tackle have a value of 1 and 0 otherwise\n",
    "    merged[\"tackle_binary_single\"] = merged.apply(\n",
    "        lambda row: 1 if ((row['tackle'] == 1 or row['assist'] == 1) and \n",
    "                          (row[\"event\"] == \"tackle\" or row[\"event\"] == \"out_of_bounds\" or row[\"event\"]==\"fumble\" or row[\"event\"]==\"qb_slide\" or row[\"event\"]==\"safety\")) else 0,\n",
    "        axis=1)    \n",
    "    print(\"done tackle_binary_single\")\n",
    "    \n",
    "    #create a new variable called tackle_nonbinary_all for the player who made the tackle or assist on a given play\n",
    "    #to have a value of 0,0.5,1 depending if it was a tackle (value of 1)  or an assist (value of 0.5)\n",
    "    merged[\"tackle_nonbinary_all\"] = merged.apply(lambda row: 1 if row['tackle'] == 1 else (0.5 if row['assist'] == 1 else 0), axis=1)\n",
    "    print(\"done tackle_nonbinary_all\")\n",
    "    \n",
    "    \n",
    "    #create a new variable called tackle_nonbinaru_sing for the player who made the tackle or assist on a given play\n",
    "    #to have a value of 0,0.5,1 depending if it was a tackle (value of 1)  or an assist (value of 0.5) at the instance of a tackle occuring\n",
    "    merged[\"tackle_nonbinary_single\"] = merged.apply(\n",
    "        lambda row: 1 if (row['tackle'] == 1 and \n",
    "                          (row[\"event\"] == \"tackle\" or row[\"event\"] == \"out_of_bounds\" or row[\"event\"] ==\"fumble\" or row[\"event\"]==\"qb_slide\" or row[\"event\"]==\"qb_slide\" or row[\"event\"]==\"safety\"))\n",
    "        else (0.5 if (row['assist'] == 1 and \n",
    "                      (row[\"event\"] == \"tackle\" or row[\"event\"] == \"out_of_bounds\" or row[\"event\"] ==\"fumble\" or row[\"event\"]==\"qb_slide\" or row[\"event\"]==\"qb_slide\" or row[\"event\"]==\"safety\")) else 0),\n",
    "        axis=1)\n",
    "    print(\"done tackle_non_binary_single\")\n",
    "\n",
    "    #return gameId, playId, frameId, nflId, tackle\n",
    "    return merged[[\"gameId\",\"playId\",\"frameId\",\"nflId\",\n",
    "                   \"tackle_binary_all\",\"tackle_binary_single\", \"tackle_nonbinary_all\", \"tackle_nonbinary_single\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dde8cd99761d16",
   "metadata": {},
   "source": [
    "# Ball Carrier Data\n",
    "\n",
    "The following function will assign vital data about the ball carrier to the tracking of each play. This includes weight (in lbs), x and y coordinates on the field, speed, acceleration, orientation, direction, force, and position of the ball Carrier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24a4d71d3a76980d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:06.611944Z",
     "start_time": "2023-12-07T19:23:06.604102Z"
    }
   },
   "outputs": [],
   "source": [
    "# ballCarrierData: takes plays, tracking, and players data to compute important data to include ball carrier data\n",
    "#                  for each tracking aspect in our data\n",
    "# input: plays, tracking, players\n",
    "# output: a dataframe of all ball carrier information on a given play and frame\n",
    "# usage: tracking.merge(ballCarrierData(plays,tracking,players), on = [\"gameId\", \"playId\", \"frameId\"])\n",
    "def ballCarrierData(plays,tracking,players):\n",
    "    plays_tracking = tracking.merge(plays, on = ['gameId','playId'], how = 'inner') #merge plays and tracking\n",
    "\n",
    "    #subset data to obtain all information of ball carriers\n",
    "    ball_carrier_tracking = plays_tracking[plays_tracking[\"nflId\"]==plays_tracking[\"ballCarrierId\"]]\n",
    "\n",
    "    ball_carrier_tracking = ball_carrier_tracking.merge(players[[\"nflId\", \"weight\", \"position\"]], on = \"nflId\", how = \"left\")\n",
    "\n",
    "    ball_carrier_tracking = ball_carrier_tracking[[\"gameId\", \"playId\", \"frameId\",\"x\", \"y\", \"s\", \"a\", \"o\", \"dir\", \"weight\", \"position\"]]\n",
    "    \n",
    "    ball_carrier_tracking[\"bcForce\"] = (ball_carrier_tracking[\"weight\"]/2.2)*ball_carrier_tracking[\"a\"]\n",
    "\n",
    "    ball_carrier_tracking.rename(columns = {\"x\":\"bcx\", \"y\": \"bcy\", \"s\": \"bcs\", \"a\": \"bca\", \"o\": \"bco\", \"dir\":\"bcdir\",\n",
    "                                           \"weight\": \"bcweight\", \"position\":\"bcPosition\"}, inplace = True)\n",
    "\n",
    "    # return dataframe with tracking on gameId, playId, nflId, frameId, and ballCarrierinfo\n",
    "    # merge with tracking\n",
    "    return ball_carrier_tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffb1d11",
   "metadata": {},
   "source": [
    "# Force and Mass\n",
    "\n",
    "The following function will compute the mass of a given player by using the listed weight in pounds from the players dataframe. This will be calculated based on weight/2.2 to obain mass in kg. The force will then be calculated by F = mass x acceleration. The resulting function will return the appropropriate dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f67b949",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T19:23:06.807463Z",
     "start_time": "2023-12-07T19:23:06.769256Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate_mass_and_force: takes the tracking and players data which computes the mass and acceleration. The mass will be calculated\n",
    "#                       based on the players listed weight. Force will be then calculate based on accleration and mass (F = ma)\n",
    "# input: tracking, players dataframes\n",
    "# output: dataframe of gameId, playId, nflId, frameId, mass, force where the dataframe can be merged with the Id values\n",
    "# usage: tracking = tracking.merge(calculate_mass_and_force(tracking, players), on = [\"gameId\", \"playId\", \"nflId\", \"frameId\"])\n",
    "def calculate_mass_and_force(tracking, players):\n",
    "    # Join tracking_df and players_df based on nflId\n",
    "    tracking_players_df = pd.merge(tracking, players, on='nflId', how='left')\n",
    "\n",
    "    # Calculate mass (assuming weight is in pounds, converting to kilograms)\n",
    "    tracking_players_df['mass'] = tracking_players_df['weight'] / 2.2\n",
    "\n",
    "    # Calculate force (assuming 'a' represents acceleration)\n",
    "    tracking_players_df['force'] = tracking_players_df['mass'] * tracking_players_df['a']\n",
    "\n",
    "    # Select the desired columns\n",
    "    result_df = tracking_players_df[['gameId', 'playId', 'nflId','frameId', 'force']]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1764ea6892aae6fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "639e7cfeef3a80d0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
